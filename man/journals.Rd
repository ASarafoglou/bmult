% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_journals.R
\docType{data}
\name{journals}
\alias{journals}
\title{Prevalence of Statistical Reporting Errors}
\format{
A \code{data.frame} with 8 rows and 14 variables:\tabular{ll}{
   Variable Name \tab Description \cr
   \code{journal} \tab The journal name a research article was published in. \cr
   \code{articles_downloaded} \tab The number of articles downloaded per journal. \cr
   \code{articles_with_NHST} \tab The number of articles with NHST results. \cr
   \code{perc_articles_with_NHST} \tab The percentage of all downloaded articles that had NHST results. \cr
   \code{nr_NHST} \tab The total number of NHST results. \cr
   \code{mean_nr_NHST_per_article_with_NHST} \tab The mean number of NHST results per article that had at least one NHST result. \cr
   \code{mean_nr_NHST_per_article_all_included} \tab The mean number of NHST results in all downloaded articles. \cr
   \code{errors} \tab The total number of errors. \cr
   \code{dec_errors} \tab The total number of decision errors (i.e., an error that may have changed the statistical conclusion of the result). \cr
   \code{perc_errors} \tab The percentage of all results that was an error. \cr
   \code{perc_dec_errors} \tab The percentage of all results that was a decision error. \cr
   \code{perc_articles_with_errors} \tab The percentage of all articles that had at least one error. \cr
   \code{perc_articles_with_dec_errors} \tab The percentage of all articles that had at least one error. \cr
   \code{APAfactor} \tab APA factor: number of detected NHST results / total number of detected p values. \cr
}
}
\usage{
data(journals)
}
\description{
This data set, "journals" provides a summary of statistical reporting errors (i.e., inconsistencies between reported test statistic
and reported p-value) of 16,695 research articles reporting results
from null hypothesis significance testing (NHST). The selected articles were published in
eight major journals in psychology between 1985 to 2013: \emph{Developmental Psychology} (DP), the \emph{Frontiers in Psychology} (FP), the
\emph{Journal of Applied Psychology} (JAP), the \emph{Journal of Consulting and Clinical Psychology} (JCCP),
\emph{Journal of Experimental Psychology: General} (JEPG), the \emph{Journal of Personality and Social Psychology} (JPSP),
the \emph{Public Library of Science} (PLoS), \emph{Psychological Science} (PS).
}
\details{
In total, \insertCite{nuijten2016prevalence; textual}{multibridge} recomputed 258,105 p-values with the software package \code{statcheck}
which extracts statistics from articles and recomputes the p-values \insertCite{epskamp2016statcheck}{multibridge}.
The anonymized dataset and the data documentation was openly available on the Open Science Framwework (\url{https://osf.io/d3ukb/};
\url{https://osf.io/c6ap2/}).
}
\examples{
data(journals)
# Prior specification 
# We assign a uniform Beta distribution on each binomial probability
a <- rep(1, 8)  
b <- rep(1, 8)  

counts <- journals$errors 
total  <- journals$nr_NHST
factor_levels <- levels(journals$journal)

# restricted hypothesis
Hr1 <- c('JAP , PS , JCCP , PLOS , DP , FP , JEPG < JPSP')
Hr2 <- c('JCCP < DP < JPSP')
Hr3 <- c('JAP < PS < JCCP < PLOS < DP < FP < JEPG < JPSP')

out <- binomBayesInformed(factor_levels, Hr1, a=a, b=b, counts=counts, total=total, niter = 5e4, bf_type = 'LogBFer'); out
out <- binomBayesInformed(factor_levels, Hr2, a=a, b=b, counts=counts, total=total, niter = 5e4, bf_type = 'LogBFer'); out
out <- binomBayesInformed(factor_levels, Hr3, a=a, b=b, counts=counts, total=total, niter = 5e4, bf_type = 'LogBFer'); out

summary(out)
}
\references{
\insertRef{nuijten2016prevalence}{multibridge}
\insertRef{epskamp2016statcheck}{multibridge}
}
\keyword{datasets}
