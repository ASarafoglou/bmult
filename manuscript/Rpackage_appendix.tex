\clearpage
\makeatletter
\efloat@restorefloats
\makeatother


\begin{appendix}
\hypertarget{transforming-an-ordered-probability-vector-to-the-real-line}{%
\section{Transforming An Ordered Probability Vector To The Real
Line}\label{transforming-an-ordered-probability-vector-to-the-real-line}}

Since we choose the multivariate normal as proposal distribution, the
mapping between the proposal and target distribution requires us to move
\(\boldsymbol{\theta}\) to the real line. Crucially this transformation
needs to retain the inequality constraints imposed on the parameters,
that is, it needs to take into account the lower bound \(l_k\) and the
upper bound \(u_k\) of each \(\theta_k\). To achieve this goal,
\textbf{multibridge} uses a probit transformation as proposed in
Sarafoglou et al. (2020) which subsequently transforms the elements in
\(\boldsymbol{\theta}\) moving from its lowest to its highest value. In
the binomial model, we move all elements in \(\boldsymbol{\theta}\) to
the real line and thus construct a new vector
\(\boldsymbol{y} \in \mathbb{R}^{K}\). For multinomial models, however,
it follows from the sum-to-one constraint that the vector
\(\boldsymbol{\theta}\) is completely determined by its first \(K - 1\)
elements of
\(\boldsymbol{\theta}: \theta_1 \leq \theta_2 \leq \cdots \leq 1 - \sum_{k = 1}^K \theta_k\).
Hence, for the transformation we will only consider the first \(K - 1\)
elements of \(\boldsymbol{\theta}\) and we will transform them to
\(K - 1\) elements of a new vector
\(\boldsymbol{y} \in \mathbb{R}^{K - 1}\).

Let \(\phi\) denote the density of a normal variable with a mean of zero
and a variance of one, \(\Phi\) denote its cumulative density function,
and \(\Phi^{-1}\) denote the inverse cumulative density function. Then
for each element \(\theta_k\), the transformation is
\[\xi_k = \Phi^{-1}\left(\frac{\theta_k - l_k}{u_k - l_k}\right),\] The
inverse transformation is given by
\[\theta_k = (u_k - l_k) \Phi(\xi_k) + l_k.\] The Jacobian of this
transformation is:
\[\left|J\right| = \prod_{k = 1}^{K - 1}  \left(u_k - l_k \right) \phi(\xi_k).\]

To perform the transformations, we thus need to determine the lower
bound \(l_k\) and the upper bound \(u_k\) of each \(\theta_k\). Assuming
\(\theta_{k-1} < \theta_{k}\) for \(k \in \{1 \cdots, K\}\) the lower
bound for any element in \(\boldsymbol{\theta}\) is defined as

\begin{align*}
  l_k = \left.
  \begin{cases}
      0 & \text{if } k = 1 \\
      \theta_{k - 1} & \text{if } 1 < k < K.
  \end{cases}
    \right.
\end{align*}

This definition holds for both binomial models and multinomial models.
Differences in these two models appear only when determining the upper
bound for each parameter, since parameters in a multinomial models are
unit constrained. For binomial models, the upper bound for each
\(\theta_k\) is simply \(1\). For multinomial models, however, the upper
bound for each \(\theta_k\) depends on the size of smaller elements as
well as on the number of remaining larger elements in
\(\boldsymbol{\theta}\). To determine the upper bound for multinomial
parameters we are using a stick-breaking method (Frigyik, Kapila, \&
Gupta, 2010; Stan Development Team, 2020). The stick-breaking approach
represents \(\boldsymbol{\theta}\) as unit-length stick which we
subsequently divide into \(K\) elements. By this definition, the upper
bound or any \(\theta_k\) is:

\begin{align}
\label{Eq:upperBound}
  u_k = \left.
  \begin{cases}
      \cfrac{1}{K} & \text{if } k = 1 \\
      \cfrac{1 - \sum_{i < k} \theta_i}{ERS} & \text{if } 1 < k < K,
  \end{cases}
    \right.
\end{align} where \(1 - \sum_{i < k} \theta_i\) represents the length of
the remaining stick, that is, the proportion of the unit-length stick
that still needs to be divided among the remaining elements in
\(\boldsymbol{\theta}\). The elements in the remaining stick are denoted
as \(ERS\), and are computed as follows: \[ERS = K - 1 + k\].

The transformations outlined above are suitable for binomial and
multinomial models featuring hypotheses in which all parameters are
inequality constrained. However, when hypotheses feature a combination
of equality and inequality constrained parameters, as well as parameters
that are free to vary we need to modify the formula to compute the upper
and lower bounds:

\begin{align}
  l_k = \left.
  \begin{cases}
      0 & \text{if } k = 1 \\
      \frac{\theta_{k - 1}}{e_{k-1}} \times e_k & \text{if } 1 < k < K,
  \end{cases}
    \right.
\end{align} where \(e_{k-1}\) refers to the number of equality
constrained parameters that are collapsed in \(\theta_{k - 1}\).

The upper bound for parameters in the binomial models still remains
\(1\). For multinomial models, the upper bound is then defined as:

\begin{align}
  u_k = \left.
  \begin{cases}
      \cfrac{1}{K} - (f_k \times l_k) & \text{if } k = 1 \\
     \left( \cfrac{1 - \sum_{i < k} \theta_i}{ERS} - (f_k \times l_k) \right) \times e_k & \text{if } 1 < k < K \text{ and } u_k \geq \text{max}(\theta_{i < k}), \\
    \left( 2 \times \left( \cfrac{1 - \sum_{i < k} \theta_i}{ERS} - (f_k \times l_k) \right) - \text{max}(\theta_{i < k}) \right)  \times e_k & \text{if } 1 < k < K \text{ and } u_k < \text{max}(\theta_{i < k}),
  \end{cases}
    \right.
\end{align} where \(f_k\) represents the number of free parameters that
share common upper and lower bounds. The elements in the remaining stick
are then computed as follows
\[ERS = e_k + \sum_{j > k} e_j \times f_j.\] The rationale behind these
modifications will be described in more detail in the following
sections. In \textbf{multibridge}, information that is relevant for the
transformation of the parameter vectors is stored in the generated
\texttt{restriction\_list} which is returned by the main functions
\texttt{binom\_bf\_informed} and \texttt{mult\_bf\_informed} but can
also be generated separately with the function
\texttt{generate\_restriction\_list}. This restriction list features the
sublist \texttt{inequality\_constraints} which encodes the number of
equality constraints collapsed in each parameter in
\texttt{nr\_mult\_equal}. Similarly the number of free parameters that
share a common bounds are encoded under \texttt{nr\_mult\_free}.

\hypertarget{equality-constrained-parameters}{%
\paragraph{Equality Constrained
Parameters}\label{equality-constrained-parameters}}

When informed hypotheses feature a mix of equality and inequality
constrained parameters, we collapse in the constrained prior and
posterior distributions all equality constrained parameters into one
category. When transforming the samples from these distributions, we
need to account for the fact that inequality constraints on the
collapsed parameters might not hold even though the constraint is valid
under the original parameter values. For instance, for
\(\theta_1 = \theta_2 = \theta_3 \leq \theta_4 \leq \theta_5\), where
the elements in \(\boldsymbol{\theta}\) take the values
\((0.15, 0.15, 0.15, 0.25, 0.3)\), the inequality constraint does not
hold for the collapsed parameters (i.e.,
\(\theta^* \nless \theta_4 \leq \theta_5\) since
\(0.45 \nleq 0.25 \leq 0.3\)). For these cases, the upper and lower
bounds for the parameters need to be adjusted as follows: \begin{align}
  l_k = \left.
  \begin{cases}
      0 & \text{if } k = 1 \\
      \frac{\theta_{k - 1}}{e_{k-1}} \times e_k & \text{if } 1 < k < K,
  \end{cases}
    \right.
\end{align} where \(e_{k-1}\) and \(e_k\) refer to the number of
equality constrained parameters that are collapsed in \(\theta_{k - 1}\)
and \(\theta_{k}\), respectively. The upper bound is defined as

\begin{align}
  u_k = \left.
  \begin{cases}
      \cfrac{1}{ERS} \times e_k & \text{if } k = 1 \\
      \cfrac{1 - \sum_{i < k} \theta_i}{ERS} \times e_k & \text{if } 1 < k < K,
  \end{cases}
    \right.
\end{align} where \(1 - \sum_{i < k} \theta_i\) represents the length of
the remaining stick and the number of elements in the remaining stick
are computed as follows: \(ERS = \sum_k^{K} e_k\). The upper bound is
then multiplied by the number of equality constrained parameters within
the current constraint.

Concretely, for the constraint above, that is
\(\theta^* \leq \theta_4\), the lower bound for \(\theta^*\) would be
\(0\). The upper bound is computed by taking into account the number of
equality constrained parameters, such that
\(u_k = \nicefrac{1}{5} \times 3 = 0.6\). For \(\theta_4\) the lower
bound is \(\nicefrac{\theta^*}{3} = 0.15\), since \(3\) parameters are
collapsed in \(\theta^*\). The upper bound for \(\theta_4\) is then
\(\cfrac{(1 - \theta^*)}{2} = 0.275\) and \(\theta_5\) is
\(1 - \theta^* - \theta_4 = 1 - 0.45 - 0.25 = 0.3\).

\hypertarget{corrections-for-free-parameters}{%
\paragraph{Corrections for Free
Parameters}\label{corrections-for-free-parameters}}

Different adjustments are required for a sequence of inequality
constrained parameters that have shared upper and lower bounds, but can
vary freely within certain upper and lower bounds. For instance, the
hypothesis \[\mathcal{H}_r: \theta_1 < \theta_2, \theta_3\] specifies
that \(\theta_2\) and \(\theta_3\) have the shared lower bound
\(\theta_1\) and the shared upper bound \(1\), however, \(\theta_2\) can
be larger than \(\theta_3\) or vice versa. To integrate these cases
within the stick-breaking approach one must account for these potential
changes of order. For these cases, the lower bounds for the parameters
remain unchanged, however the upper bounds need to be adjusted as
follows: \begin{align}
  u_k = \left.
  \begin{cases}
      \cfrac{1}{K} - (f_k \times l_k) & \text{if } k = 1 \\
      \cfrac{1 - \sum_{i < k} \theta_i}{ERS} - (f_k \times l_k) & \text{if } 1 < k < K,
  \end{cases}
    \right.
\end{align}

where \(f_k\) represents the number of free parameters that share common
upper and lower bounds. Here, the number of elements in the remaining
stick are computed as follows: \(ERS = 1 + \sum_{j > k} f_j\).
Subtracting the lower bound for the remaining free parameters from the
upper bound of the current parameter secures a minimum stick-length for
the remaining free parameters to comply with the constraint. A further
correction is required, if a preceding free parameter (i.e., a free
parameter that was already accounted for in the stick) is larger than
the upper bound of the current parameter. In that case, we need we
subtract the difference between the largest preceding free parameter in
the sequence with the current upper bound. Thus if
\(u_k < \text{max}(\theta_{i < k})\), the upper bound becomes:
\begin{align}
u_k &= u_k - (\text{max}(\theta_{i < k}) - u_k)\\
    &= 2 \times u_k - \text{max}(\theta_{i < k}).
\end{align}

To outline when such a correction is necessary, consider the constraint
\(\theta_1 \leq \theta_2, \theta_3 \leq \theta_4,\) where the elements
in \(\boldsymbol{\theta}\) take on the values
\((0.1, 0.35, 0.15, 0.40)\). When transforming the parameters, the lower
bound for \(\theta_1\) is \(0\), the upper bound \(\nicefrac{1}{4}\).
The parameters \(\theta_2\) and \(\theta_3\) share the same lower bound,
which is, \(\theta_1 = 0.1\). The upper bound for \(\theta_2\), is the
length of the remaining stick divided by the elements of the remaining
stick, that is, \(\nicefrac{0.9}{2} = 0.45\). From the resulting upper
bound, we subtract the lower bound for the remaining free parameters of
the sequence, which yields an upper bound for \(\theta_2\) of
\(0.45 - 0.1 = 0.35\). Since \(\theta_2\) is the first free parameter in
the sequence that is evaluated an additional downward correction is not
necessary. The upper bound for \(\theta_3\) is
\((1 - 0.1 - 0.35)/2 = 0.275\). However, if \(\theta_3\) would actually
take on the value \(0.275\), \(\theta_4\) would need to be \(0.275\)
too, which would violate the constraint (i.e.,
\(0.1 \leq 0.35, 0.275 \nleq 0.275\)). Therefore, we apply the
additional correction, such that \begin{align}
  u_k &= 2 \times u_k - \text{max}(\theta_{i < k}) \\
      &= 2 \times 0.275 - 0.35 \\
      &= 0.2,
\end{align} which secures the proper ordering for the remainder of the
parameters, since \(\theta_4 = 0.2\) would yield
\(0.1 \leq 0.35, 0.2 \leq 0.35\).

\hypertarget{references}{%
\subsection{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-frigyik2010introduction}{}%
Frigyik, B. A., Kapila, A., \& Gupta, M. R. (2010). \emph{Introduction
to the Dirichlet distribution and related processes}. Department of
Electrical Engineering, University of Washington.

\leavevmode\hypertarget{ref-sarafoglou2020evaluatingPreprint}{}%
Sarafoglou, A., Haaf, J. M., Ly, A., Gronau, Q. F., Wagenmakers, E., \&
Marsman, M. (2020). Evaluating multinomial order restrictions with
bridge sampling. \emph{PsyArXiv}. Retrieved from
\url{https://psyarxiv.com/bux7p/}

\leavevmode\hypertarget{ref-stan2020}{}%
Stan Development Team. (2020). \emph{Stan modeling language user's guide
and reference manual, version 2.23.0}. R Foundation for Statistical
Computing. Retrieved from \url{http://mc-stan.org/}
\end{cslreferences}

\endgroup
\end{appendix}
