---
title             : "multibridge: An R Package To Evaluate Multinomial Order Constraints"
shorttitle        : "multibridge"

author: 
  - name          : "Alexandra Sarafoglou"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, PO Box 15906, 1001 NK Amsterdam, The Netherlands"
    email         : "alexandra.sarafoglou@gmail.com"
  - name          : "Julia M. Haaf"
    affiliation   : "1"
  - name          : "Frederik Aust"
    affiliation   : "1"
  - name          : "Eric-Jan Wagenmakers"
    affiliation   : "1"
  - name          : "Maarten Marsman"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Amsterdam"

abstract: |
  The \textbf{multibridge} package has been developed to efficiently compute Bayes factors for binomial and multinomial models, that feature inequality constraints, equality constraints, free parameters and mixtures between them. By using the bridge sampling algorithm to compute the Bayes factor, \textbf{multibridge} facilitates the evaluation of large models with many constraints and models with very small parameter spaces. The package was developed in the R programming language and is freely available from the Comprehensive \texttt{R} Archive Network (CRAN). We illustrate the functions based on two empirical examples.

bibliography      : "../inst/REFERENCES.bib"
appendix          : "Rpackage_appendix.Rmd"

floatsintext      : no
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
biblio-style      : "apa"
output            : papaja::apa6_pdf
header-includes:
   - \usepackage{bm}
   - \usepackage{amsmath}
   - \usepackage{nicefrac}
   - \usepackage{caption}
   - \usepackage{xcolor}
   - \definecolor{mypink}{RGB}{255, 230, 255}
   - \definecolor{myWheat}{RGB}{245, 222, 179}
   - \definecolor{myGreen}{RGB}{27, 158, 119}
   - \usepackage{todonotes}
   - \newcommand{\Julia}[1]{\todo[inline, color=mypink]{#1}}
   - \newcommand{\Frederik}[1]{\todo[inline, color=myWheat]{#1}}
   - \newcommand{\Alex}[1]{\todo[inline, color=myGreen]{#1}}
---

```{r, echo = FALSE, warning=FALSE}
library(plyr)
library(knitr)
```


# Introduction

We present \textbf{multibridge}, an \texttt{R} package to evaluate informed hypotheses in multinomial models and models featuring independent binomials using Bayesian inference. This package allows users to specify constraints on the underlying category proportions including inequality constraints, equality constraints, free parameters and mixtures between them. This package is available from the Comprehensive \texttt{R} Archive Network (CRAN) at \url{https://CRAN.R-project.org/package=multibridge}. Here we introduce the methodology used to evaluate informed hypotheses on categorical variables and show how to use the implementations provided in \textbf{multibridge} through fully reproducible examples.

The most common way to analyze categorical variables is to test whether the underlying category proportions are exactly equal or whether they are fixed and follow a predicted pattern. Often however, scientific hypotheses go beyond this standard case and predict for instance ordinal relations among the underlying category proportions, such as increasing or decreasing trends. For instance, to check for irregularities in audit data, one could test whether the leading digits in the data are distributed according to an expected Benford distribution or whether they deviate from it by, for example, showing a general decreasing trend. In the following, we will denote predictions about ordinal relations as informed hypotheses. Informed hypotheses can also feature combinations of equality and inequality constrained parameters, as well as parameters that are free to vary. For instance, when studying the prevalence of statistical reporting errors in articles published in different areas of psychological science, one could hypothesize that articles published in social psychology journals have higher error rates than articles published in other psychological journals while not expressing expectations about the error rate distribution among these other journals [@nuijten2016prevalence]. Generally, testing informed hypotheses allows researchers to specify hypotheses that relate more closely to their theories. 

In the Bayesian framework, researchers can compare models that instantiate the hypotheses of interest by means of Bayes factors [@jeffreys1935some; @kass1995bayes]. Bayes factors compare the relative evidence of two hypotheses--for instance, the informed hypothesis versus a hypothesis that lets all parameters free to vary--in the light of the data. The \textbf{multibridge} package is intended to facilitate the computation of Bayes factors quantifying evidence for or against informative models easily. Several available \texttt{R} packages allow users to evaluate order constrained hypotheses. The package \textbf{multinomineq} [@heck2019multinomial] is available to evaluate ordinal relations for multinomial models as well as models that feature independent binomials. \textbf{multinomineq} allows users to specify inequality constrained hypotheses but also more general linear inequality constraints. The \textbf{BAIN} [@gu2019bain] package allows for the evaluation of inequality constraints in structural equation models. Outside of \texttt{R}, the Fortran 90 program \textbf{BIEMS} [@mulder2012biems] allows for the evaluation of order constraints for multivariate linear models such as MANOVA, repeated measures, and multivariate regression. All these packages rely on one of two methods to approximate order constrained Bayes factors: the encompassing prior approach [@gu2014bayesian; @klugkist2005bayesian; @hoijtink2008bayesian; @hoijtink2011informative] and the conditioning method [@mulder2009bayesian; @mulder2014prior; @mulder2016bayes]. Even though these methods are currently widely used, they are known to become increasingly unreliable and inefficient as the number of constraints increases or when the parameter space of the constrained model is small [@sarafoglou2020evaluatingPreprint].

In contrast to these available packages, \textbf{multibridge} uses a bridge sampling routine that enables users to compute Bayes factors for informed hypotheses more reliably and efficiently [@bennett1976efficient; @meng1996simulating; @sarafoglou2020evaluatingPreprint]. The workhorse for this analysis, the bridge sampling algorithm, constitutes a special case of the algorithm implemented in the \texttt{R} package \textbf{bridgesampling} [@gronau2017bridgesampling]. With \textbf{bridgesampling}, users are able to estimate the marginal likelihood for a wide variety of models, including models implemented in Stan [@stan2020]. However, \textbf{bridgesampling} is not suitable for models that include constraints on probability vectors. In \textbf{multibridge}, we therefore tailored the bridge sampling algorithm such that it accommodates the specification of informed hypotheses on probability vectors. The general workflow of \textbf{multibridge} is illustrated in Figure \@ref(fig:scheme-multibridge).

(ref:scheme-multibridge-caption) The \textbf{multibridge} workflow. The user needs to specify the data values (\texttt{x} and \texttt{n} for binomial models and \texttt{x} for multinomial models, respectively), the informed hypothesis (\texttt{Hr}), the $\alpha$ and $\beta$ parameters of the Binomial prior distributions (\texttt{a} and \texttt{b}) or the concentration parameters for the Dirichlet prior distribution (\texttt{a}), respectively, and the factor levels (\texttt{factor\_levels}). The functions \texttt{mult\_bf\_informed} and \texttt{binom\_bf\_informed} then produce an estimate for the Bayes factor of the informed hypothesis versus the encompassing hypothesis in which all parameters are free to vary. Based on these results different S3 methods can be used to get more detailed information on the individual components of the analysis (\texttt{summary}, \texttt{bayes\_factor}), and parameter estimates of the encompassing distribution (\texttt{plot}).

```{r scheme-multibridge, fig.cap='(ref:scheme-multibridge-caption)', out.width = "400px", message=FALSE}
knitr::include_graphics("scheme_multibridge.png", auto_pdf = TRUE)
```

The package produces an estimate for the Bayes factor in favor of or against the informed hypothesis. The resulting Bayes factor compares the evidence for the informed hypotheses to the encompassing hypothesis that imposes no constraints on the underlying category proportions. Given this result, the user can then either receive a visualization of the prior and posterior parameter estimates using the \texttt{plot}-method, or get more detailed information on how the Bayes factors is composed using the \texttt{summary}-method. For hypotheses that include mixtures between equality and inequality informed hypotheses the \texttt{bayes\_factor} method shows the conditional Bayes factor for the inequality constraints given the equality constraints and a Bayes factor for the equality constraints. Table \ref{table:s3_methods} summarizes all S3 methods currently available in \textbf{multibridge}.

\begin{table}
\caption {S3 methods available in $\textbf{multibridge}$}
\label{table:s3_methods}
\begin{center}
\begin{tabular}{p{4cm}p{3.5cm}p{9cm}}
        \toprule
Function Name(s) & S3 Method & Description \\\midrule
$\texttt{mult\_bf\_informed}$, $\texttt{binom\_bf\_informed}$ & $\texttt{print}$ & Prints model specifications and descriptives. \\
 & $\texttt{summary}$ &  Prints and returns the Bayes factor and associated hypotheses for the full model, and all equality and inequality constraints.\\
  & $\texttt{plot}$ &  Plots the posterior median and 95\% credible interval of the parameter estimates of the encompassing model.\\
 & $\texttt{bayes\_factor}$ & Contains all Bayes factors and log marginal likelihood estimates for inequality constraints.\\
 & $\texttt{samples}$ & Extracts prior and posterior samples from constrained distribution (if bridge sampling was applied). \\
& $\texttt{bridge\_output}$    &  Extracts bridge sampling output and associated error measures.\\
& $\texttt{restriction\_list}$ & Extracts restriction list and associated informed hypothesis. \\
$\texttt{binom\_bf\_inequality}$, $\texttt{binom\_bf\_inequality}$  & $\texttt{print}$ & Prints the bridge sampling estimate for the log marginal likelihood and the corresponding percentage error. \\
& $\texttt{summary}$ & Prints and returns the bridge sampling estimate for the log marginal likelihood and associated error terms.\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

<!-- The following signs can be used to encode informed hypotheses: "\texttt{<}" and "\texttt{>}" for inequality constraints, "\texttt{=}" for equality constraints, "\texttt{,}" for free parameters, and "\texttt{\&}" for independent hypotheses. The restricted hypothesis can either be a string or a character vector. For instance, the hypothesis \texttt{c("theta1 < theta2, theta3")} means, that (1) $\theta_1$ is smaller than both \texttt{theta_2} and \texttt{theta_3}, and (2) \texttt{theta_2} and \texttt{theta_3} are both bigger than \texttt{theta_1}, but are not influenced by each other. The hypothesis \texttt{c("theta1 < theta2 = theta3 \& theta4 > theta5")} means that (1) two independent hypotheses are stipulated: "\texttt{theta1 < theta2 = theta3}" and "\texttt{theta4 > theta5}", (2) the restrictions on the parameters \texttt{theta_1}, \texttt{theta_2}, and \texttt{theta_3} do not influence the restrictions on the parameters \texttt{theta_4} and \texttt{theta_5}, (3) \texttt{theta_1}is smaller than \texttt{theta_2} and \texttt{theta_3}, (4) \texttt{theta_2} and \texttt{theta_3} are assumed to be equal, and (5) \texttt{theta_4} is larger than \texttt{theta_5}. -->

The remainder of this article is organized as follows: In the methods section, we describe the Bayes factor identity for informed hypotheses in binomial and multinomial models, and present the bridge sampling routine implemented in the \textbf{multibridge} package including details of the necessary transformations required for this routine. In Section 3, we will schematically introduce the most relevant functions in \textbf{multibridge} and their arguments. Section 4 illustrates how to use the \textbf{multibridge} package to estimate parameters, and compute Bayes factors using two examples.

# Methods

\textbf{multibridge} allows users to specify informed hypotheses in multinomial models and models that feature independent binomial probabilities. In the multinomial model, two assumes that the vector of observations $x_1, \cdots, x_K$ in the $K$ categories follow a multinomial distribution. The parameter vector of the multinomial model, $\theta_1, \cdots, \theta_K$, contains the probabilities of observing a value in a particular category. The parameter vector $\theta_1, \cdots, \theta_K$ is drawn from a Dirichlet distribution with concentration parameters $\alpha_1, \cdots, \alpha_K$. Formally, the model can be described as follows:

\begin{align}
  x_1, \cdots, x_K &\sim \text{Multinomial}(\sum_{k = 1}^K x_k, \theta_1, \cdots, \theta_K) \\
  \theta_1, \cdots, \theta_K &\sim \text{Dirichlet}(\alpha_1, \cdots, \alpha_K).
\end{align}

In the binomial model, we assume that the elements in the vector of successes $x_1, \cdots, x_K$ and the elements in the vector of total number of observations $n_1, \cdots, n_K$ in the $K$ categories follow independent binomial distributions. As in the multinomial model, the parameter vector of the binomial success probabilities, $\theta_1, \cdots, \theta_K$, contains the probabilities of observing a value in a particular category. The parameter vector $\theta_1, \cdots, \theta_K$ are drawn from independent beta distributions with parameters $\alpha_1, \cdots, \alpha_K$ and $\beta_1, \cdots, \beta_K$. The model can be described as follows:

\begin{align}
  x_1 \cdots x_K & \sim \prod_{k = 1}^K \text{Binomial}(\theta_k, n_k) \\
  \theta_1 \cdots \theta_K &\sim \prod_{k = 1}^K \text{Beta}(\alpha_k, beta_k).
\end{align}

## Bayes factor

When evaluating informed hypotheses that feature mixtures between inequality and equality constraints it is important to realize that the Bayes factor, further denoted as $\text{BF}_{me}$, factors follows:

$$
\text{BF}_{me}
= \text{BF}_{0e} \times \text{BF}_{re} \mid \text{BF}_{0e},
$$
where the subscript $m$ denotes a hypothesis that features mixtures of inequality and equality constraints. A Bayes factor for mixtures thus factors into a Bayes factor for the equality constraints, $\text{BF}_{0e}$, and  a conditional Bayes factor for the inequality constraints given the equality constraints $\text{BF}_{re} \mid \text{BF}_{0e}$.

## The Bayes Factor For Equality Constraints

For binomial models, the (marginal) Bayes factor for the equality constraints can be computed analytically with the function \texttt{binom_bf_equality}. Assuming that the first $i$ binomial probabilities in a model are equality constrained, the Bayes factor $\text{BF}_{0e}$ is defined as:
\begin{align*}
\text{BF}_{0e} &=
&= \cfrac{\prod_{i < k} \text{B}(\alpha_i\text{, } \beta_i)}{\prod_{i < k} \text{B}(\alpha_i + x_i\text{, } \beta_i + n_i - x_i)} \times \cfrac{\text{B}(\alpha_+ + x_+ - i + 1\text{, } \beta_+ + n_+ - x_+ - i + 1)}{\text{B}(\alpha_+ - i + 1\text{, } - i + 1)}
\end{align*}
where $\text{B}()$ denotes the beta function and $\alpha_+ = \sum_{i<k}\alpha_i$, $\beta_+ = \sum_{i<k}\beta_i$, $x_+ = \sum_{i<k} x_i$ and $n_+ = \sum_{i<k} n_i$. The latter factor introduces a correction for marginalizing which stems from the change in degrees of freedom, when we collapse $i$ equality constraint parameters: For $i$ collapsed categories, $i - 1$ degrees of freedom are lost which are subtracted from the prior parameters in the corresponding Binomial distribution. 

For multinomial models, the (marginal) Bayes factor for the equality constraints can also be computed analytically with the function \texttt{multBayes_bf_equality}. Assuming again that the first $i$ category probabilities in a model are equality constraint, the Bayes factor $\text{BF}_{0e}$ is defined as:
\begin{align*}
\text{BF}_{e0} = \frac{\text{B}(\boldsymbol{\alpha})}{\text{B}(\boldsymbol{\alpha}+\mathbf{x})} \, \left(\frac{1}{i}\right)^{\sum_{i<k} x_i}\,\frac{\text{B}\left(\sum_{i<k}\alpha_i+x_i - i + 1\text{, }\alpha_{k}+x_{k}\text{, }\dots\text{, }\alpha_K+x_K\right)}{
 \text{B}\left(\sum_{i<k}\alpha_i - i + 1\text{, }\alpha_{k}\text{, }\dots\text{, }\alpha_K\right)},
\end{align*}

## The Bayes Factor For Inequality Constraints

For inequality constrained hypotheses, @klugkist2005bayesian derived the following identity of the Bayes factor $\text{BF}_{re}$: 

\begin{align}
\label{Eq:klugkistIdentity}
\text{BF}_{re} &= \cfrac{\overbrace{p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathbf{x}\text{, }\mathcal{H}_e)}^{\substack{\text{Proportion of posterior parameter}\\\text{space consistent with the restriction}}}}{\underbrace{p(\boldsymbol{\theta} \in \mathcal{R}_r \mid  \mathcal{H}_e)}_{\substack{\text{Proportion of prior parameter}\\\text{space consistent with the restriction}}}},
\end{align}

where in $\text{BF}_{re}$, the subscript $r$ denotes the inequality constrained hypothesis and the subscript $e$ denotes the encompassing hypothesis that lets all parameters free to vary. Recently, however, @sarafoglou2020evaluatingPreprint showed that the Bayes factor $\text{BF}_{re}$ can also be interpreted as ratio of two marginal likelihoods:

\begin{align}
\label{Eq:sarafoglouIdentity}
\text{BF}_{re} =
\cfrac{\overbrace{p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathbf{x}\text{, }\mathcal{H}_e)}^{\substack{\text{Marginal likelihood of}\\\text{posterior distribution}}}}{\underbrace{p(\boldsymbol{\theta} \in \mathcal{R}_r \mid  \mathcal{H}_e)}_{\substack{\text{Marginal likelihood of}\\\text{prior distribution}}}}.
\end{align}

In this identity, $p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathbf{x}\text{, }\mathcal{H}_e)$ denotes the marginal likelihood of the constrained posterior distribution and $p(\boldsymbol{\theta} \in \mathcal{R}_r \mid  \mathcal{H}_e)$ denotes the marginal likelihood of the constrained prior distribution. Even though both identities are mathematically equivalent, the methods to estimate these identities are very different. 
In the first case, for instance, the number of samples from the encompassing distribution in accordance with the inequality constrained hypothesis, serve as an estimate for the proportion of prior parameter space consistent with the restriction. On the flip side, however, this means that the accuracy of this estimate is strongly dependent on the number of the constrained parameters in the model and the size of the constrained parameter space. That is, as the constraints become stronger, the constrained parameter space decreases. As a result it becomes less likely that draws from the encompassing distribution will fall into the constrained region, so that in some cases the estimation of the Bayes factor becomes practically impossible [@sarafoglou2020evaluatingPreprint].

However, when we interpret the Bayes factor $\text{BF}_{re}$ as ratio of marginal likelihoods and we are able to sample from the constrained prior and posterior distributions, we can utilize numerical sampling methods such as bridge sampling to obtain the estimates. Crucially, in this approach, it does not matter how small the constrained parameter space is in proportion to the encompassing density. This gives the method a decisive advantage over the encompassing prior approach in terms of accuracy and efficiency especially (1) when binomial and multinomial models with relatively high number of categories (i.e., $K > 10$) are evaluated and (2) when relatively little posterior mass falls in the constrained parameter space.

<!-- ### PUT THIS LATER -->
<!-- The conditional Bayes factor of inequality constraints given the equality constraints involves expectations over the conditional Binomial distributions -->
<!-- $$ -->
<!-- p(\boldsymbol{\theta}_r \mid \boldsymbol{\theta}_0 \in\mathcal{R}_0\text{, }\mathcal{H}_e) =  \text{Binomial}\left(\sum_{i<k}\alpha_k-j+1\text{, }\sum_{i<k}\beta_k-j+1\right) \times \prod_{k=j + 1}^K -->
<!-- \text{Binomial}\left(\alpha_{k}\dots\text{, }\beta_{k}\right) -->
<!-- $$ -->
<!-- and -->
<!-- $$ -->
<!-- p(\boldsymbol{\theta}_r \mid \boldsymbol{\theta}_0 \in \mathcal{R}_0\text{, }\mathbf{x}\text{, }\text{, }\mathbf{n}\text{, }\mathcal{H}_e) = \text{Binomial}\left(\sum_{i<k}(\alpha_k + x_k) -j+1 \text{, }\sum_{i<k} (\beta_k + n_k - x_k) -j+1 \right) \times \prod_{k=j + 1}^K -->
<!-- \text{Binomial}\left(\alpha_{k}\dots\text{, }\beta_{k}\right), -->
<!-- $$ -->
<!-- whose marginal likelihoods are approximated using bridge sampling. -->
<!-- The conditional Bayes factor of inequality constraints given the equality constraints involves expectations over the conditional Dirichlet distributions -->
<!-- $$ -->
<!-- p(\boldsymbol{\theta}_r \mid \boldsymbol{\theta}_0 \in\mathcal{R}_0\text{, }\mathcal{H}_e) = \text{Dirichlet}\left(\sum_{i<k}\alpha_k-j+1\text{, }\alpha_{j+1}\dots\text{, }\alpha_K\right) -->
<!-- $$ -->
<!-- and -->
<!-- $$ -->
<!-- p(\boldsymbol{\theta}_r \mid \boldsymbol{\theta}_0 \in \mathcal{R}_0\text{, }\mathbf{x}\text{, }\mathcal{H}_e) = \text{Dirichlet}\left(\sum_{i<k}(\alpha_k+x_k)-j+1\text{, }\alpha_{j+1}+x_{j+1}\dots\text{, }\alpha_K+x_K\right). -->
<!-- $$ -->


## The Bridge Sampling Method

Bridge sampling is a method to estimate the ratio of two marginal likelihoods which yield the Bayes factor [@bennett1976efficient; @meng1996simulating]. In the \textbf{multibridge} package we implemented a version of bridge sampling that estimates one marginal likelihood at the time since it increases the accuracy of the method without considerably increasing its computational efficiency [@overstall2010default]. Specifically, we subsequently estimate the marginal likelihood for the constrained prior distribution and the marginal likelihood of the constrained posterior distribution.

When applying this modified version of the bridge sampling method, we estimate a marginal likelihood by means of a so-called proposal distribution. In \textbf{multibridge} this proposal distribution is the multivariate normal distribution. To estimate the marginal likelihood, bridge sampling only requires samples from the distribution of interest---the so-called target distribution---and samples from the proposal distribution. In \textbf{multibridge}, the samples from the target distribution---that is the constrained prior and posterior Dirichlet distribution for multinomial models and constrained prior and posterior beta distributions for binomial models---are drawn through the Gibbs sampling algorithms proposed by @damien2001sampling. For binomial models, we apply the suggested Gibbs sampling algorithm for constrained beta distributions. In the case of the multinomial models, however, we apply an algorithm that simulates values from constrained Gamma distributions which are then transformed into Dirichlet random variables (for details, see Appendix C in @sarafoglou2020evaluatingPreprint). To sample efficiently from these distributions, \textbf{multibridge} uses a \texttt{C++} routine for this algorithm.

The efficiency of the bridge sampling method is guaranteed only if the target and proposal distribution (1) operate on the same parameter space and (2) have sufficient overlap. To meet these requirements, \textbf{multibridge} applies the appropriate probit transformations on the samples of the constrained distributions to move the samples from the probability space to the entire real line. Details on these transformations are provided in the appendix. To ensure sufficient overlap, half of the draws are then used to construct the proposal distribution using the method of moments. Samples from the proposal distribution can be generated using the standard \texttt{rmvnorm}-function from the \texttt{R} package \textbf{stats}. For the marginal likelihood of the constrained prior distribution, the modified bridge sampling identity is then defined as:

\begin{align}
    p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e) = \cfrac{\mathbb{E}_{g(\boldsymbol{\theta})}\left(p(\boldsymbol{\theta}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\theta}\in\mathcal{R}_r)h(\boldsymbol{\theta})\right)}{\mathbb{E}_{\text{prior}} \left(g(\boldsymbol{\theta})h(\boldsymbol{\theta})\right)},
    \label{Eq:bridgeidentity}
\end{align}
where the term $h(\boldsymbol{\theta})$ refers to the bridge function proposed by @meng1996simulating which minimized the relative mean square error of the estimate and $g(\boldsymbol{\theta})$ refers to the proposal distribution. The numerator evaluates the unnormalized density for the constrained prior distribution with samples from the proposal distribution. The denominator evaluates the normalized proposal distribution with samples from the constrained prior distribution. The expression for the marginal likelihood for the constrained posterior distribution can be described in a similar way. As final step, we apply the iterative scheme proposed by @meng1996simulating to receive the bridge sampling estimator:

\begin{align*}
    \hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t+1)} \approx \cfrac{\cfrac{1}{N_2} \sum_{m = 1}^{N_2} \cfrac{\ell_{2,m}}{s_1 \ell_{2,m} + s_2 p(\boldsymbol{\tilde \theta_m} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t)}}}
    {\cfrac{1}{N_1} \sum_{n = 1}^{N_1} \cfrac{1}{s_1 \ell_{1,n} + s_2 p(\boldsymbol{\theta^*_n} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t)}}},
    %\label{Eq:bridgeIterativeScheme}
\end{align*}
where $N_1$ denotes the number of samples drawn from the constrained distribution, that is, $\boldsymbol{\theta}^* \sim p(\boldsymbol{\theta} \mid \mathcal{H}_r)$, $N_2$ denotes the number of samples drawn from the proposal distribution, that is $\boldsymbol{\tilde \theta} \sim g(\boldsymbol{\theta})$,
$s_1 = \frac{N_1}{N_2 + N_1}$, and $s_2 = \frac{N_2}{N_2 + N_1}$. The quantities $\ell_{1,n}$ and $\ell_{2,m}$ are defined as follows:

\begin{align}
    \ell_{1,n} &= \cfrac{q_{1,1}}{q_{1,2}}  = \cfrac{p(\boldsymbol{\theta^*_n}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\theta^*_n}\in\mathcal{R}_r)}{g(\boldsymbol{\xi_n}^*)},\\
    \ell_{2,m} &= \cfrac{q_{2,1}}{q_{2,2}} = \cfrac{p(\boldsymbol{\tilde \theta_m}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\tilde \theta_m}\in\mathcal{R}_r)}{g(\boldsymbol{\tilde \xi_m})},
\end{align}
where $\boldsymbol{\xi_n}^* = \Phi^{-1}\left(\cfrac{\boldsymbol{\theta^*_n} - \mathbf{l}}{\mathbf{u} - \mathbf{l}}\right)$, and $\boldsymbol{\tilde \theta_m} = ((\mathbf{u} - \mathbf{l})\Phi(\boldsymbol{\tilde \xi_m}) + \mathbf{l}) \left|J\right|)$. The quantity $q_{1,1}$ refers to the evaluations of the constrained distribution for constrained samples and $q_{1,2}$ refers to the proposal evaluations for constrained samples, respectively. The quantities $q_{2,1}$ refers to evaluations of the constrained distribution for samples from the proposal and $q_{2,2}$ refers to the proposal evaluations for samples from the proposal, respectively. Note that the quantities $\ell_{1,n}$ and $\ell_{2,m}$ have been adjusted to account for the necessary parameter transformations to create overlap between the constrained distributions and the proposal distribution. \textbf{multibridge} runs the iterative scheme until the tolerance criterion suggested by @gronau2017tutorial is reached, that is, $\cfrac{\mid \hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t + 1)} - \hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t)} \mid}{\hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t + 1)}} \leq 10^{-10}$.

The bridge sampling estimate for the log marginal likelihood of the constrained distribution and its associate relative mean square error, the number of iterations, and the quantities $q_{1,2}$, $q_{1,2}$, $q_{1,2}$, and $q_{1,2}$ are included in the standard output in \textbf{multibridge}. The function to compute the relative mean square error was taken from the R package \textbf{bridgesampling}.\Frederik{Is this important enough to mention it here?}

# Usage and Examples


The \textbf{multibridge} package can be installed from the Comprehensive R Archive Network (CRAN) at
\url{https://CRAN.R-project.org/package=multibridge}:

```{r, echo = TRUE, eval = FALSE}
install.packages('multibridge')
library('multibridge')
```

```{r, echo = FALSE}
library('multibridge')
```

The two core functions of \textbf{multibridge}---the \texttt{mult\_bf\_informed}-function and the \texttt{binom\_bf\_informed}-function---can be illustrated schematically as follows:

```{r, eval=FALSE, echo=TRUE}
mult_bf_informed(x, Hr, a factor_levels)
binom_bf_informed(x, n, Hr, a, b, factor_levels)
```

The basic required arguments for these functions are listed in Table \ref{tab:arguments}.

\begin{table}
\caption{To estimate the Bayes factor in favor for or against the specified informed hypothesis, the user provides the core functions \texttt{mult\_bf\_informed} and \texttt{binom\_bf\_informed} with the following basic required arguments}
\label{tab:arguments}
\begin{center}
\begin{tabular}{p{4cm}p{12cm}}
        \toprule
Argument & Description \\\midrule
\texttt{x} & a vector with data (for multinomial models) or a vector of counts of successes, or a two-dimensional table (or matrix) with 2 columns, giving the counts of successes and failures, respectively (for binomial models)  \\
\texttt{n} &  numeric. Vector of counts of trials. Must be the same length as \texttt{x}. Ignored if \texttt{x} is a matrix or a table \\
\texttt{Hr} & string or character. Encodes the user specified informed hypothesis. Users can either use the specified \texttt{factor\_levels} or indexes to refer to parameters.\\
\texttt{a} & numeric. Vector with concentration parameters of Dirichlet distribution (for multinomial models) or $\alpha$ parameters for independent beta distributions (for binomial models). Default sets all parameters to 1 \\
\texttt{b} & numeric. Vector with $\beta$ parameters. Must be the same length as \texttt{x}. Default sets all $\beta$ parameters to 1 \\
\texttt{factor\_levels} &  character. Vector with category names. Must be the same length as \texttt{x}\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

A list of all currently available functions and datasets is given in Table \ref{table:core_functions}. Additional examples are available as vignettes (see \url{https://cran.r-project.org/package=multibridge}, or `vignette(package = "multibridge")`).

\begin{table}
\caption {Core functions available in $\textbf{multibridge}$}
\label{table:core_functions}
\begin{center}
\begin{tabular}{p{5cm}p{11cm}}
        \toprule
Function Name(s) & Description \\\midrule
$\texttt{mult\_bf\_informed}$ & Evaluates informed hypotheses on multinomial parameters.  \\
$\texttt{mult\_bf\_inequality}$ & Estimates the marginal likelihood of a constrained prior or posterior Dirichlet distribution.  \\
$\texttt{mult\_bf\_equality}$ & Computes Bayes factor for equality constrained multinomial parameters using the standard Bayesian multinomial test.  \\
$\texttt{mult\_tsampling}$ & Samples from truncated prior or posterior Dirichlet density.\\
$ \texttt{lifestresses}, \texttt{peas}$ & Datasets associated with informed hypotheses in multinomial models.\\\midrule
$\texttt{binom\_bf\_informed}$ & Evaluates informed hypotheses on binomial parameters.  \\
$\texttt{binom\_bf\_inequality}$ & Estimates the marginal likelihood of constrained prior or posterior beta distributions.\\
$\texttt{binom\_bf\_equality}$ & Computes Bayes factor for equality constrained binomial parameters.  \\
$\texttt{binom\_tsampling}$ & Samples from truncated prior or posterior beta densities.\\
$ \texttt{journals}$ & Dataset associated with informed hypotheses in binomial models.\\\midrule
$ \texttt{generate\_restriction\_list}$ & Encodes the informed hypothesis.\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

In the following, we will outline two examples on how to use \textbf{multibridge} to compare an informed hypothesis to a null or encompassing hypothesis. In addition, the first example shows how two informed hypotheses can be compared to each other.

## Example 1: Applying A Benford Test to Greek Fiscal Data

The first digit phenomenon, otherwise known as Benford's law [@benford1938law; @newcomb1881note] states that the expected proportion of leading digits in empirical data can be formalized as follows: for any given leading digit $d, d = (1, \cdots, 9)$ the expected proportion is approximately equal to $$\mathbb{E}_{\theta_d}= \text{log}_{10}((d + 1)/d).$$ This means that a number in a empirical dataset has leading digit $1$ in $30.1 \%$ of the cases, and leading digit $2$ in $17.61 \%$ of the cases; leading digit $9$ is the least frequent digit with an expected proportion of only $4.58 \%$ (see Table \ref{Tab:benford} for an overview of the expected proportions). @benford1938law showed that his law applies to a broad range of real-world data; among others, it applies to data on population sizes, death rates, baseball statistics, atomic weights of elements, and physical constants. In contrast, generated data, such as telephone numbers, do in general not obey Benford's law [@hill1995statistical]. Since Benford's law proved to be highly suitable to discriminate between empirical data and generated data, a so-called Benford test can be used in fields like accounting and auditing as an indication for poor data quality (for an overview, see e.g., @durtschi2004effective, @nigrini1997use, @nigrini2012benford). A Benford test typically checks whether observed frequencies of first digits, for instance, from fiscal statements, obey Benford's law. Data that do not pass the Benford test, should raise audit risk concerns, meaning that, it is recommended that the data undergo additional follow-up checks [@nigrini2019patterns].

In the following, we discuss three possible Bayesian adaptations of Benford's test. In a first scenario we simply conduct Bayesian multinomial test in which we test the point-null hypothesis $\mathcal{H}_0$ which predicts a Benford distribution against the encompassing hypothesis $\mathcal{H}_{e}$ which leaves all model parameters free to vary. Testing against the encompassing hypothesis is considered standard practice, yet, it leads to an unfair comparison to the detriment of the null hypothesis. In general, if we are dealing with a high-dimensional parameter space and the competing hypotheses differ largely in their complexity, the Bayes factor generally favors the less complex hypothesis even if the data follow the predicted trend of the more complex hypothesis considerably well. In a second scenario we therefore test the null hypothesis against an alternative hypothesis, denoted as $\mathcal{H}_{r1}$, which predicts a decreasing trend in the proportions of leading digits. The hypothesis $\mathcal{H}_{r1}$ implies considerably more constraints than $\mathcal{H}_{e}$ and is a suitable choice if our primary goal is to distinguish whether data comply with Benford's law or whether the data only follow a similar trend. In a third scenario we could be interested in testing the null hypothesis against an alternative hypothesis, which predicts a trend that is characteristic for manipulated data. This alternative hypothesis, which we denote as $\mathcal{H}_{r2}$, could be derived from empirical research on fraud or be based on observed patterns from former fraud cases. For instance, @hill1988random instructed students to produce a series of random numbers; in the resulting data the proportion of the leading digit $1$ occurred most often and the digits $8$ and $9$ occurred least often which is consistent with the general pattern of Benford's law. However, the proportion for the remaining leading digits were approximately equal. We do want to note, that the predicted distribution derived from @hill1988random is not currently used as a test to detect manipulated data patterns. However, for the sake of simplicity, if we assume that this pattern could be an indication for completely invented auditing data, the Bayes factor could quantify the evidence of whether the proportion of first digits resemble authentic or invented data.

### Data and Hypothesis

<!-- # ```{r, echo = FALSE} -->
<!-- # dat0        <- read.table('EUAuditing.csv', header=TRUE, sep=',') -->
<!-- # greece_dat  <- dat0[1:9, grepl('Greece_', colnames(dat0))] -->
<!-- # greece_N    <- unlist(dat0[10, grepl('Greece_', colnames(dat0))]) -->
<!-- # for(i in 1:ncol(greece_dat)){ -->
<!-- #   greece_dat[, i] <- greece_dat[, i] * greece_N[i] -->
<!-- # } -->
<!-- # # round numbers to receive integers -->
<!-- # greece_dat$all <- round(rowSums(greece_dat)) -->
<!-- # dat <- data.frame(leading_digit = 1:9, -->
<!-- #                   benford_proportions = dat0$Benford[1:9], -->
<!-- #                   observed_counts = greece_dat$all, -->
<!-- #                   observed_proportions = greece_dat$all/sum(greece_dat$all)) -->
<!-- # ``` -->

The data we use to illustrate the computation of Bayes factors were originally published by the European statistics agency "Eurostat" and served as basis for reviewing the adherence to the Stability and Growth Pact of EU member states. @rauch2011fact conducted a Benford test on data related to budget deficit criteria, i.e., public deficit, public dept and gross national products. This data used for this example contains fiscal data from Greece related in the years between $1999$ and $2010$; a total of $N= 1{,}497$ numerical data were included in the analysis. We choose this data, since the Greek government deficit and debt statistics states has been repeatedly criticized by the European Commission in this timespan [@europeanCommision2004; @europeanCommision2010]. In particular, the commission has accused the Greek statistical authorities, to have misreported deficit and debt statistics. For further details on the dataset see @rauch2011fact. The observed proportions are displayed in Table \ref{Tab:benford}, the figure displaying the observed versus the expected proportions are displayed in Figure \ref{fig:benford}.

\begin{table}[h]
	\centering
	\caption{The Table shows the Observed Counts, Observed Proportions, and Expected Proportions of first digits in Greece governmental data. The total sample size was $N = 1{,}497$ observations. Note that the observed proportions and counts deviate slightly from those reported in Rauch et al. (2011) (probably due to rounding errors).}
	\begin{tabular}{cccp{4cm}}
		\hline
Leading digit & Observed Counts & Observed Proportions & Expected Proportions: Benford's Law  \\
		\hline
		1 & 509 & 0.340 & 0.301  \\
		2 & 353 & 0.236 & 0.176  \\
		3 & 177 & 0.118 & 0.125  \\
		4 & 114 & 0.076 & 0.097  \\
		5 & 77 & 0.051 & 0.079  \\
		6 & 77 & 0.051 & 0.067  \\
		7 & 53 & 0.035 & 0.058  \\
		8 & 73 & 0.049 & 0.051  \\
		9 & 64 & 0.043 & 0.046  \\
		\hline
	\end{tabular}
    \label{Tab:benford}
\end{table}

In this example, the parameter vector of the multinomial model, $\theta_1, \cdots, \theta_K$, reflects the probabilities of a leading digit in the Greek fiscal data being a number from $1$ to $9$.  Thus, we can formalize the discussed hypotheses as follows. The null hypothesis specifies that the proportions of first digits obeys Benford's law:
$$\mathcal{H}_0 : \boldsymbol{\theta}_0 = (0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046).$$

We are testing the null hypothesis against the following alternative hypotheses:
\begin{align*}
\mathcal{H}_e &: \boldsymbol{\theta} \sim \text{Dirichlet}(\boldsymbol{\alpha}), \\
\mathcal{H}_{r1} &: \theta_1 > \theta_2 > \theta_3 > \theta_4 > \theta_5 > \theta_6 > \theta_7 > \theta_8 > \theta_9, \\
\mathcal{H}_{r2} &:  \theta_1 > (\theta_2 = \theta_3 = \theta_4 = \theta_5 = \theta_6 = \theta_7) > (\theta_8, \ \theta_9).
\end{align*}

In cases, in which we are interested in computing two informed hypotheses with each other, we need to make use of the transitivity property of the Bayes factor. For instance, if we would like to compare the two inequality-constrained hypotheses $\mathcal{H}_{r1}$ and $\mathcal{H}_{r2}$ with each other, we would first compute $\text{BF}_{er1}$ and $\text{BF}_{er2}$ and then yield $\text{BF}_{r1r2}$ as follows:
$$\text{BF}_{r1e} \times \text{BF}_{er2} = \text{BF}_{r1r2}.$$

### Method
We can compare $\mathcal{H}_0$ and $\mathcal{H}_e$ by means of a Bayesian multinomial test, that is, we stipulate equality constraints on the entire parameter vector $\boldsymbol{\theta}$. The corresponding Bayes factor is thus computationally straightforward; we can calculate $\text{BF}_{0e}$ by applying the function \texttt{mult\_bf\_equality}. To evaluate $\mathcal{H}_0$, we only need to specify (1) a vector with observed counts, (2) a vector with concentration parameters, and (3) the vector of predicted proportions. Since we have no specific expectations about the distribution of leading digits in the Greek fiscal data, we choose in all subsequent analyses the uniform Dirichlet distribution as prior for the vector of model parameters.

```{r, message=FALSE, echo = TRUE, results='hide'}
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Prior specification
a <-  rep(1, 9)
# Expected proportions
p <- log10((1:9 + 1)/1:9)
# Execute the analysis
results_H0_He  <- mult_bf_equality(x = x, a = a, p = p)
```

Since the hypotheses $\mathcal{H}_{r1}$ and $\mathcal{H}_{r2}$  contain inequality constraints, we use the function \texttt{mult\_bf\_informed} to compute the Bayes factor of the informed hypotheses to the encompassing hypothesis. To evaluate $\mathcal{H}_{r1}$ and $\mathcal{H}_{r2}$, we need to specify
(1) a vector containing the number of observations, (2) the inequality-constrained hypotheses,
(3) a vector with concentration parameters, and (4) labels for the categories of interest
(i.e., leading digits):

```{r, message=FALSE, echo = TRUE, results='hide'}
# Labels for categories of interest
factor_levels <- 1:9
# Specifying the informed Hypothesis (step 3)
Hr1 <- c('1 > 2 > 3 > 4 > 5 > 6 > 7 > 8 > 9')
Hr2 <- c('1 > 2 = 3 = 4 = 5 = 6 = 7 > 8 > 9')
# Execute the analysis
results_He_Hr1 <- mult_bf_informed(x = x, Hr = Hr1, a = a, 
                                 factor_levels = factor_levels, 
                                 seed = 2020)
results_He_Hr2 <- mult_bf_informed(x = x, Hr = Hr2, a = a, 
                                 factor_levels = factor_levels, 
                                 seed = 2020)
```

```{r, echo = TRUE, results='hide'}
logbf <- c(log(results_H0_He$bf$BF0e),
           log(results_H0_He$bf$BF0e * results_He_Hr1$bf_list$bf$BFer),
           log(results_H0_He$bf$BF0e * results_He_Hr2$bf_list$bf$BFer))
bayes_factor_table <- data.frame(
   BFType = c('LogBF0e', 'LogBF0r1', 'LogBF0r2'), 
   LogBF  = logbf)
bayes_factor_table
```

As the evidence is extreme in all three cases, we reported all Bayes factors on the log scale which allows us to compare the numbers more easily. The log Bayes factor $\text{log}(\text{BF}_{e0})$ suggests extreme evidence against the hypothesis that the first digits in the Greek fiscal data follow a Benford's distribution; $\text{log}(\text{BF}_{0e}) =$ `r bayes_factor_table[1, 2]`. The log Bayes factor $\text{log}(\text{BF}_{er1})$ indicates extreme evidence in favor for a decreasing trend, $\text{log}(\text{BF}_{0r1}) =$ `r bayes_factor_table[2, 2]`. Only for the hypothesis that the data follow a pattern of fraudulent data, we yield extreme evidence in favor for the null hypothesis, that is, $\text{log}(\text{BF}_{er2}) =$ `r bayes_factor_table[3, 2]`. Overall, these results suggest that the data deviate from the Benford distribution.
The proportions of leading digits is best characterized by a monotonously decreasing trend, compared to all parameters varying freely ($\text{log}(\text{BF}_{r1e}) =$ `r signif(-results_He_Hr1$bf_list$bf$LogBFer, 3)`), and compared to a distribution that one could expect from completely invented data ($\text{log}(\text{BF}_{r1r2}) =$ `r signif(-bayes_factor_table[2,2] + bayes_factor_table[3,2], 3)`).

(ref:benford-caption) The bargraph displays the expected proportions of leading digits according to Benford's law. The black dots indicate for the actual fiscal statistics from Greece the posterior estimates for the proportion of leading digits and the corresponding 95\% credible intervals based on the encompassing model. Only three out of nine estimates cover the expected proportions.

```{r benford, echo = FALSE, message = FALSE, fig.cap = "(ref:benford-caption)"}
xaxis_position <- c(0.8, 2, 3.2, 4.4, 5.6, 6.8, 8, 9.2, 10.4)
estimates <- summary(results_He_Hr1)$estimates
b <- barplot(p, las = 1, xlab = " ", ylab = " ", col = "grey", cex.lab = 1.7,
    cex.main = 1.5, axes = FALSE, ylim = c(0, 0.4))
points(xaxis_position, estimates$median, cex = 1.5, lwd = 2, pch = 19)
#lines(xaxis_position, estimates$median, lwd = 2, type = "c")
l_ply(seq_along(estimates$median), function(x) arrows(x0 = xaxis_position[x], y0 = estimates$lower[x], x1 = xaxis_position[x],
    y1 = estimates$upper[x], code = 3, length = 0.1, angle = 90, lwd = 1.5))
axis(1, xaxis_position, 1:9, cex.axis = 1.3)
axis(2, seq(0, 0.4, by = 0.1), cex.axis = 1.3, las = 1)
#lines(xaxis_position, dat$benford_proportions, lwd = 2, type = "c")
mtext("Leading Digit", side = 1, line = 2.5, cex = 1.5, font = 2)
mtext("Proportion", side = 2, line = 3, cex = 1.5, font = 2)
```

### Discussion

In this example we tested the data quality of Greek fiscal data in the years 1999 to 2009 by conducting three variations of a Bayesian Benford test. More precisely, we evaluated the null hypothesis that the data conform to Benfords law. We tested this hypothesis against three alternatives. The first alternative hypothesis, $\mathcal{H}_e$ relaxed the constraints imposed by the null hypothesis and left all model parameters free to vary. The second alternative hypothesis, $\mathcal{H}_{r1}$ predicted a decreasing trend in the proportion of leading digits. The third alternative hypothesis $\mathcal{H}_{r2}$ predicted a trend that @hill1988random observed when humans tried to generate random numbers. Our result suggest that the leading digits in the fiscal statistics do not follow a Benford distribution; in fact, we collected extreme evidence against Benford's law compared to two out of three of the alternative hypotheses. When comparing the alternative hypotheses directly to each other, the data show most evidence in favor for a decreasing trend. A Benford test of fiscal statements can be a helpful tool to detect poor data quality and suspicious numbers. In follow-up checks of these numbers, it could then be examined for instance, whether financial statements were actually materially misstated (by, for instance, rounding up or down numbers, avoiding certain thresholds etc., Nigrini, 2019).

## Example 2: Prevalence of Statistical Reporting Errors

In any scientific article that uses null hypothesis significance testing, there is a chance that the reported test statistic and degrees of freedom, do not match the reported $p$-value. In most cases this is because researchers copy the relevant test statistics by hand into their articles and there are no automatic checks to detect these mistakes. Therefore, @epskamp2014statcheck developed the R package \texttt{statcheck}, which only requires the PDF of a given scientific article to detect these reporting errors automatically and efficiently. This package allowed @nuijten2016prevalence to get an overview about the prevalence of statistical reporting errors in the field of psychology. In total, the authors investigated a sample of $30{,}717$ articles (which translates to over a quarter of a million $p$-values) published in eight major psychological journals between 1985 to 2013: *Developmental Psychology* (DP), the *Frontiers in Psychology* (FP), the *Journal of Applied Psychology* (JAP), the *Journal of Consulting and Clinical Psychology* (JCCP), *Journal of Experimental Psychology: General* (JEPG), the *Journal of Personality and Social Psychology* (JPSP), the *Public Library of Science* (PLoS), *Psychological Science* (PS).

Besides the overall prevalence of statistical reporting errors across these journals, the authors were interested whether there is a higher prevalence for reporting inconsistencies in certain subfields in psychology compared to others. In this context the possibility was raised that there exists a relationship between the prevalence for reporting inconsistencies and questionable research practices. Specifically, the authors argued that besides honest mistakes when transferring the test statistics into the manuscript, statistical reporting error occur when authors misreport $p$-values, for instance, by incorrectly rounding them down below $0.05$. Based on this assumption @nuijten2016prevalence predicted that the proportion of statistical reporting errors should be highest in articles published in the *Journal of Personality and Social Psychology* (JPSP), compared to other journals, since researchers in social psychology were shown to have the highest prevalence for questionable research practices [@john2012measuring]. Specifically, @john2012measuring found that researchers from the area of social psychology assessed questionable research practices both as more defensible and more applicable for their research compared to other research areas in psychology. 

### Data and Hypothesis

We use the original data published zn by @nuijten2016prevalence, which we also distribute with the package \textbf{multibridge} under the name `journals`.

```{r, echo = TRUE}
# load the data
data(journals)
```

The hypothesis of interest,$\mathcal{H}_r$, formulated by @nuijten2016prevalence states that the prevalence for statistical reporting errors for articles published in social psychology journals (i.e., JPSP) is higher than for articles published in other journals. We will test this hypothesis against the the null hypothesis $\mathcal{H}_0$ that all journals have the same prevalence for statistical reporting errors. In this example, the parameter vector of the binomial success probabilities, $\boldsymbol{\theta}$, reflects the probabilities of a statistical reporting error in one of the 8 journals. Thus, we can formalize the discussed hypotheses as follows:

\begin{align*}
    \mathcal{H}_r &: (\theta_{\text{DP}}, \theta_{\text{FP}}, \theta_{\text{JAP}} , \theta_{\text{JCCP}} , \theta_{\text{JEPG}} , \theta_{\text{PLoS}}, \theta_{\text{PS}}) < \theta_{\text{JPSP}} \\
    \mathcal{H}_0 &: \theta_{\text{DP}} =  \theta_{\text{FP}} =  \cdots = \theta_{\text{JPSP}}.
\end{align*}

### Method
To compute the Bayes factor $\text{BF}_{0r}$ we need to specify (1) a vector with observed successes, and (2) a vector containing the total number of observations, (3) the informed hypothesis, (4) a vector with prior parameter $\alpha_i$ for each binomial proportion, (5) a vector with prior parameter $\beta_i$ for each binomial proportion, and (6) the categories of interest (i.e., journal names). With this information, we can now conduct the analysis with the function `binom_bf_informed`. 

```{r, echo=TRUE, message=FALSE, results='hide'}
# Since percentages are rounded to two decimal values, we round the
# articles with an error to obtain integer values
x <- round(journals$articles_with_NHST  * 
             (journals$perc_articles_with_errors/100))

# Total number of articles
n <- journals$articles_with_NHST

# Prior specification
# We assign a uniform beta distribution to each binomial proportion
a <- rep(1, 8)
b <- rep(1, 8)

# Specifying the informed Hypothesis
Hr <- c('JAP , PS , JCCP , PLOS , DP , FP , JEPG < JPSP')

# Category labels
journal_names <- journals$journal

# Execute the analysis
results_H0_Hr <- binom_bf_informed(x = x, n = n, Hr = Hr, a = a, b = b,
                               factor_levels = journal_names,
                               bf_type = 'BF0r', seed = 2020)

BFre <- results_H0_Hr$bf_list$bfr_table['BFre']
BFe0 <- results_H0_Hr$bf_list$bf0_table['BFe0']
BFr0 <- results_H0_Hr$bf_list$bf['BFr0']
```

The data suggest that the null hypothesis is highly unlikely; we find extreme evidence against the null hypothesis with a log Bayes factor $\text{log}(\text{BF}_{0e})$ of `r signif(log(BFe0), 3)`.

We collected moderate evidence for the informed
hypothesis. Specifically, the results suggest that the data
are `r signif(BFre, 3)` more likely under
the informed hypothesis that the social psychology journal JPSP 
has the highest prevalence for statistical reporting errors than under the hypothesis that the ordering
of the journals can vary freely. 

The Bayes factor $\text{log}(\text{BF}_{r0})$ suggests extreme evidence for the informed hypothesis; $\text{log}(\text{BF}_{r0}) =$ `r signif(log(BFr0), 3)`.

In order to get a clearer picture about the ordering of the journals, we can investigate the posterior estimates
under the encompassing model as the next step. The posterior median and 95\% credible interval are returned the \texttt{summary}-method and can be plotted, too:

(ref:journals-caption) The figure displays for each journal the posterior estimates for the prevalence that an article includes a statistical reporting error and the corresponding 95\% credible intervals based on the encompassing model. It appears that all journals show a relatively similar prevalence for statistical reporting errors, with the exception of the *Journal of Applied Psychology* (JAP) and *Psychological Science* (PS), whose prevalence is much lower.

```{r journals, echo = FALSE, message = FALSE, fig.cap = "(ref:journals-caption)"}
plot(summary(results_H0_Hr))
```

### Discussion

In this example, we tested whether the prevalence for statistical reporting errors for articles published in social psychology journals (i.e., JPSP) is higher than for articles published in other journals. We tested this hypothesis against the null hypothesis that the prevalence for statistical reporting errors is equal across all journals. The resulting Bayes factor of $\text{BF}_{r0} = `r papaja:::typeset_scientific(signif(BFr0, 3))`$ provides extreme evidence for the informed hypothesis. However, this result should be interpreted with caution and be considered more differentiated. It seems that the result is above all an indication that the null hypothesis is highly misspecified and that the prevalence for a statistical reporting error varies greatly from journal to journal. Evidence that JPSP stands out and has a higher prevalence than the other journals is relatively small; the data provided only moderate evidence against the encompassing hypotheses.

# Summary

The \texttt{R} package \textbf{multibridge} facilitates the computation of Bayes factors for informed hypotheses in multinomial models. The underlying algorithm is based on a recently developed bridge sampling routine that is more efficient and reliable than available methods. \textbf{multibridge} can evaluate hypotheses that feature equality constraints, inequality constraints, and free parameters as well as mixtures between them. The core functions of the software package were illustrated with two empirical examples. The \textbf{multibridge} package is under continuous development. In the future, we aim to implement methods that extend the functionality of the package to hierarchical binomial and multinomial models. In addition, we want to enable users to specify order constraints that are more complex, including hypotheses on the size ratios of the parameters of interest or the difference between category proportions.

\clearpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

```{r echo = FALSE, results = 'asis', cache = FALSE}
papaja::render_appendix('Rpackage_appendix.Rmd')
```

