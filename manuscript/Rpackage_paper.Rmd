---
title             : "multibridge: An R Package To Evaluate Informed Hypotheses in Binomial and Multinomial Models" 
shorttitle        : "multibridge"

author:
  - name: Alexandra Sarafoglou
    affiliation: ' '
    role:
      - Conceptualization
      - Data Curation
      - Formal Analysis
      - Funding Acquisition
      - Methodology
      - Project Administration
      - Software
      - Validation
      - Visualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
    corresponding: yes
    address: 'Alexandra Sarafoglou, Department of Psychology, PO Box 15906, 1001 NK Amsterdam, The Netherlands, E-mail: alexandra.sarafoglou@gmail.com'
  - name: Frederik Aust
    affiliation: ' '
    role:
      - Conceptualization
      - Software
      - Supervision
      - Validation
      - Visualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name: Maarten Marsman
    affiliation: ' '
    role:
      - Funding Acquisition
      - Conceptualization
      - Methodology
      - Supervision
      - Validation
      - Writing - Review & Editing
  - name: Eric-Jan Wagenmakers
    affiliation: ' '
    role:
      - Funding Acquisition
      - Methodology
      - Supervision
      - Validation
      - Writing - Review & Editing
  - name: Julia M. Haaf
    affiliation: ' '
    role:
      - Conceptualization
      - Formal Analysis
      - Methodology
      - Software
      - Supervision
      - Validation
      - Writing - Original Draft Preparation
      - Writing - Review & Editing

affiliation:
  - id: ' '
    institution: University of Amsterdam

abstract: |
  The \textbf{multibridge} \texttt{R} package allows a Bayesian evaluation of informed hypotheses \(\mathcal{H}_r\) applied to frequency data from an independent binomial or multinomial distribution. \textbf{multibridge} uses bridge sampling to efficiently compute Bayes factors for the following hypotheses concerning the latent category proportions \(\boldsymbol{\theta}\): (a) hypotheses that postulate equality constraints (e.g., \(\theta_1 = \theta_2 = \theta_3\)); (b) hypotheses that postulate inequality constraints (e.g., \(\theta_1 < \theta_2 < \theta_3\) or \(\theta_1 > \theta_2 > \theta_3\)); (c) hypotheses that postulate mixtures of inequality constraints and equality constraints (e.g., \(\theta_1 < \theta_2 = \theta_3\)); and (d) hypotheses that postulate mixtures of (a)--(c) (e.g., \(\theta_1 < (\theta_2 = \theta_3) , \theta_4\)). Any informed hypothesis \(\mathcal{H}_r\) may be compared against the encompassing hypothesis \(\mathcal{H}_e\) that all category proportions vary freely, or against the null hypothesis \(\mathcal{H}_0\) that all category proportions are equal. \textbf{multibridge} facilitates the fast and accurate comparison of large models with many constraints and models for which relatively little posterior mass falls in the restricted parameter space. This paper describes the underlying methodology and illustrates the use of \textbf{multibridge} through fully reproducible examples.

bibliography      : "../inst/REFERENCES.bib"

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
numbersections    : true

documentclass     : "apa6"
classoption       : "man"
biblio-style      : "apa"
output            : papaja::apa6_pdf
header-includes:
   - \usepackage{bm}
   - \usepackage{amsmath}
   - \usepackage{nicefrac}
   - \usepackage{caption}
   - \usepackage{xcolor}
   - \definecolor{mypink}{RGB}{255, 230, 255}
   - \definecolor{myWheat}{RGB}{245, 222, 179}
   - \definecolor{myGreen}{RGB}{27, 158, 119}
   - \usepackage{todonotes}
   - \usepackage[toc]{appendix}
   - \newcommand{\Julia}[1]{\todo[inline, color=mypink]{#1}}
   - \newcommand{\Frederik}[1]{\todo[inline, color=myWheat]{#1}}
   - \newcommand{\Alex}[1]{\todo[inline, color=myGreen]{#1}}
---

```{r, echo = FALSE, warning=FALSE}
library(plyr)
library(knitr)
```

# Introduction

\noindent The most common way to analyze categorical variables is to conduct either binomial tests, multinomial tests, or chi-square goodness of fit tests. These tests compare the encompassing hypothesis to a null hypothesis that all underlying category proportions are either exactly equal, or follow a specific distribution. Accordingly, these tests are suitable when theories predict either the invariance of all category proportions or specific values. For instance, chi-square goodness of fit tests are commonly used to test Benford's law, which predicts the distribution of leading digits in empirical datasets [@benford1938law; @newcomb1881note]. Often, however, the predictions that researchers are interested in are of a different kind. Consider for instance the weak-order mixture model of decision-making  [@regenwetter2012behavioral]. The theory predicts that individuals' choice preferences are weakly ordered at all times, that is, if they prefer choice \(A\) over \(B\) and \(B\) over \(C\) then they will also prefer \(A\) over \(C\) [@regenwetter2011transitivity]---a well-constrained prediction of behavior. The theory is, however, silent about the exact values of each choice preference. Hence, the standard tests that compare \(\mathcal{H}_e\) to \(\mathcal{H}_0\) are unsuited to test the derived predictions. Instead, the predictions need to be translated into an informed hypothesis \(\mathcal{H}_r\) that reflects the predicted ordinal relations among the parameters. Only then is it possible to adequately test whether the theory of weakly-ordered preference describes participants' choice behavior. Of course, researchers may be interested in more complex hypotheses, including ones that feature combinations of equality constraints, inequality constraints, and unconstrained category proportions. For instance, @nuijten2016prevalence hypothesized that articles published in social psychology journals would have higher error rates than articles published in other psychology journals. As in the previous example, the authors had no expectations about the exact error rate distribution across journals. Here, again, the standard tests are inadequate. Generally, by specifying informed hypotheses researchers and practitioners are able to ``add theoretical expectations to the traditional alternative hypothesis'' [@hoijtink2008bayesian, p. 2] and thus test hypotheses that relate more closely to their theories [@haaf2019capturngPreprint; @rijkeboer2008psychologists].

In the Bayesian framework, researchers may test hypotheses of interest by means of Bayes factors [@jeffreys1935some; @kass1995bayes]. Bayes factors quantify the extent to which the data change the prior model odds to the posterior model odds, that is, the extent to which one hypothesis outpredicts the other. Specifically, Bayes factors are the ratio of marginal likelihoods of the respective hypotheses. For instance, the Bayes factor for the informed hypothesis versus the encompassing hypothesis is defined as:
\begin{align*}
\text{BF}_{re} = \cfrac{\overbrace{p(\mathbf{x}\mid \mathcal{H}_r)}^{\substack{\text{Marginal likelihood}\\\text{under $\mathcal{H}_r$}}}}{\underbrace{p(\mathbf{x}\mid \mathcal{H}_e)}_{\substack{\text{Marginal likelihood}\\\text{under $\mathcal{H}_e$}}}},
\end{align*}
where the subscript \(r\) denotes the informed hypothesis and \(e\) denotes the encompassing hypothesis. Several available \texttt{R} packages compute Bayes factors for informed hypotheses. For instance, the package \textbf{multinomineq} [@heck2019multinomial] evaluates informed hypotheses for multinomial models as well as models that feature independent binomials. The package \textbf{BFpack} [@mulderBfpackInPress] evaluates informed hypotheses for statistical models such as univariate and multivariate normal linear models, generalized linear models, special cases of linear mixed models, survival models, and relational event models. The package \textbf{BAIN} [@gu2019bain] evaluates informed hypotheses for structural equation models. Outside of \texttt{R}, the Fortran 90 program \textbf{BIEMS} [@mulder2012biems] evaluates informed hypotheses for multivariate linear models such as MANOVA, repeated measures, and multivariate regression. All these packages rely on one of two implementations of the encompassing prior approach [@klugkist2005bayesian; @sedransk1985bayesian] to approximate order constrained Bayes factors: the unconditional encompassing method [@klugkist2005bayesian ; @hoijtink2008bayesian; @hoijtink2011informative] and the conditional encompassing method [@gu2014bayesian; @laudy2006bayesian; @mulder2009bayesian; @mulder2014prior; @mulder2016bayes]. Even though the encompassing prior approach is currently the most common method to evaluate informed hypotheses, it becomes increasingly unreliable and inefficient as the number of restrictions increases or the parameter space of the restricted model decreases [@sarafoglou2020evaluatingPreprint]. 

As alternative to the encompassing prior approach, @sarafoglou2020evaluatingPreprint recently proposed a bridge sampling routine [@bennett1976efficient; @meng1996simulating] that computes Bayes factors for informed hypotheses more reliably and efficiently. This routine is implemented in \textbf{multibridge} (\url{https://CRAN.R-project.org/package=multibridge}) and is suitable to evaluate inequality constraints for multinomial and binomial models. When an informed hypothesis includes mixtures of equality and inequality constraints, the core functions in \textbf{multibridge} split the hypothesis to compute Bayes factors separately for equality constraints (for which the Bayes factor has an analytic solution) and inequality constraints (for which the Bayes factor is estimated using bridge sampling). The core functions of \textbf{multibridge}, that is \(\texttt{mult\_bf\_informed}\) and \(\texttt{binom\_bf\_informed}\), return the Bayes factor estimate in favor of or against the informed hypothesis (see Table \ref{table:arguments} for a summary of the basic required arguments of the two core functions). In addition, users can visualize the posterior parameter estimates under the encompassing hypothesis using the \texttt{plot}-method, or get more detailed information on how the Bayes factor is composed using the \texttt{summary}-method. For hypotheses that include mixtures between equality and inequality constrained hypotheses the \texttt{bayes\_factor} method separately returns the Bayes factor for the equality constraints and the conditional Bayes factor for the inequality constraints given the equality constraints. The informed hypothesis can be conveniently specified using a string or character vector. Furthermore, the transitivity property of Bayes factors can be used to test two informed hypotheses against each other (see Example 1 for an illustration). The general workflow of \textbf{multibridge} is illustrated in Figure \ref{fig:scheme-multibridge}. Table \ref{table:s3_methods} summarizes all S3 methods currently available in \textbf{multibridge}.

(ref:scheme-multibridge-caption) The \textbf{multibridge} workflow. When calling \texttt{mult\_bf\_informed} or \texttt{binom\_bf\_informed}, the user specifies the data values (\texttt{x} and \texttt{n} for binomial models and \texttt{x} for multinomial models, respectively), the informed hypothesis (\texttt{Hr}), the \(\alpha\) and \(\beta\) parameters of the binomial prior distributions (\texttt{a} and \texttt{b}) or the concentration parameters for the Dirichlet prior distribution (\texttt{a}), respectively, and the category labels of the factor levels (\texttt{factor\_levels}). The functions then return the estimated Bayes factor for the informed hypothesis relative to the encompassing or the null hypothesis. Based on these results different S3 methods can be used to get more detailed information on the individual components of the analysis (e.g., \texttt{summary}, \texttt{bayes\_factor}), and parameter estimates of the encompassing distribution (\texttt{plot}).

```{r scheme-multibridge, fig.cap='(ref:scheme-multibridge-caption)', out.width = "500px", message=FALSE}
knitr::include_graphics("scheme_multibridge.png", auto_pdf = TRUE)
``` 
\clearpage

\begin{table}[H]
\caption{To estimate the Bayes factor in favor for or against the specified informed hypothesis, the user provides the core functions \texttt{mult\_bf\_informed} and \texttt{binom\_bf\_informed} with the basic required arguments listed below.}
\label{table:arguments}
\begin{center}
\begin{tabular}{p{4cm}p{12cm}}
        \toprule
Argument & Description \\\midrule
\texttt{x} & \texttt{numeric}. Vector with data (for multinomial models) or a vector of counts of successes, or a two-dimensional table (or matrix) with 2 columns, giving the counts of successes and failures, respectively (for binomial models).  \\
\texttt{n} &  \texttt{numeric}. Vector with counts of trials. Must be the same length as \texttt{x}. Ignored if \texttt{x} is a matrix or a table. Included only in \texttt{binom\_bf\_informed}. \\
\texttt{Hr} & \texttt{string} or \texttt{character}. String or vector with the user specified informed hypothesis. Parameters may be referenced by the specified \texttt{factor\_levels} or by numerical indices.\\
\texttt{a} & \texttt{numeric}. Vector with concentration parameters of Dirichlet distribution (for multinomial models) or $\alpha$ parameters for independent beta distributions (for binomial models). Must be the same length as \texttt{x}. Default sets all parameters to 1. \\
\texttt{b} & \texttt{numeric}. Vector with $\beta$ parameters. Must be the same length as \texttt{x}. Default sets all $\beta$ parameters to 1. Included only in \texttt{binom\_bf\_informed}.\\
\texttt{factor\_levels} &  \texttt{character}. Vector with category labels. Must be the same length as \texttt{x}.\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{table}[H]
\caption {S3 methods available in $\textbf{multibridge}$.}
\label{table:s3_methods}
\begin{center}
\begin{tabular}{p{4cm}p{3.5cm}p{9cm}}
        \toprule
Function Name(s) & S3 Method & Description \\\midrule
$\texttt{mult\_bf\_informed}$, $\texttt{binom\_bf\_informed}$ & $\texttt{print}$ & Prints model specifications and descriptives. \\
 & $\texttt{summary}$ &  Prints and returns the Bayes factor and associated hypotheses for the full model, and all equality and inequality constraints.\\
  & $\texttt{plot}$ & Plots the posterior median and credible interval of the parameter estimates of the encompassing model. Default sets credible interval to 95\%.\\
 & $\texttt{bayes\_factor}$ & Contains all Bayes factors and log marginal likelihood estimates for inequality constraints.\\
 & $\texttt{samples}$ & Extracts prior and posterior samples from constrained densities (if bridge sampling was applied). \\
& $\texttt{bridge\_output}$  &  Extracts bridge sampling output and associated error measures.\\
& $\texttt{restriction\_list}$ & Extracts restriction list and associated informed hypothesis. \\
$\texttt{mult\_bf\_inequality}$, $\texttt{binom\_bf\_inequality}$  & $\texttt{print}$ & Prints the bridge sampling estimate for the log marginal likelihood and the corresponding percentage error. \\
& $\texttt{summary}$ & Prints and returns the bridge sampling estimate for the log marginal likelihood and associated error terms.\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\noindent This paper showcases how the proposed bridge sampling routine by @sarafoglou2020evaluatingPreprint can be applied in a user-friendly way with \textbf{multibridge}. In the remainder of this article, we will describe the Bayes factor identity for informed hypotheses in binomial and multinomial models, and briefly describe the bridge sampling method. Then, we illustrate the core functions of \textbf{multibridge} package using two examples and end with a brief summary.

# Methods

\noindent In this section we formalize multinomial models and models that feature independent binomial probabilities as they have been implemented in \textbf{multibridge}. In the multinomial model, we assume that the vector of observations \textbf{x} in the \(K\) categories follows a multinomial distribution in which the parameters of interest, \(\boldsymbol{\theta}\), represent the underlying category proportions. Since the \(K\) categories are dependent, the vector of probability parameters is constrained to sum to one, such that \(\sum_{k = 1}^K (\theta_1, \cdots, \theta_K) = 1\). Therefore, a suitable choice for a prior distribution for \(\boldsymbol{\theta}\) is the Dirichlet distribution with concentration parameter vector \(\boldsymbol{\alpha}\):

\begin{align}
  x_1, \cdots, x_K &\sim \text{Multinomial}(\sum_{k = 1}^K x_k, \theta_1, \cdots, \theta_K) \\
  \theta_1, \cdots, \theta_K &\sim \text{Dirichlet}(\alpha_1, \cdots, \alpha_K),
\end{align}
where \(\boldsymbol{\alpha}\) can be interpreted as vector of \emph{a priori} category counts. The formalization of the model for independent binomial probabilities is similar since the multinomial model above constitutes a generalization of the binomial model (for \(K \geq 2\)). In the binomial model, we assume that the elements in the vector of successes \textbf{x} and the elements in the vector of total number of observations \textbf{n} in the \(K\) categories follow independent binomial distributions. As in the multinomial model, the parameter vector of the binomial success probabilities \(\boldsymbol{\theta}\) contains the underlying category proportions, however, in this model we assume that categories are independent which removes the sum-to-one constraint. Therefore, a suitable choice for a prior distribution for \(\boldsymbol{\theta}\) is a vector of independent beta distributions with parameters \(\boldsymbol{\alpha}\) and \(\boldsymbol{\beta}\):

\begin{align}
  x_1 \cdots x_K & \sim \prod_{k = 1}^K \text{Binomial}(\theta_k, n_k) \\
  \theta_1 \cdots \theta_K &\sim \prod_{k = 1}^K \text{Beta}(\alpha_k, \beta_k),
\end{align}
where $\boldsymbol{\alpha}$ can be interpreted as vector of \emph{a priori} successes that observations fall within the various categories and \(\boldsymbol{\beta}\) can be interpreted as vector of \emph{a priori} failures.

## Bayes factor

\noindent \textbf{multibridge} features two different methods to compute Bayes factors: one method computes Bayes factors for equality constrained parameters and one method computes Bayes factors for inequality constrained parameters. Both methods will be outlined below. In cases where informed hypotheses feature mixtures between inequality and equality constraints, we compute the overall Bayes factor \(\text{BF}_{re}\) by multiplying the individual Bayes factors for both constraint types. This is motivated by the fact that the Bayes factor for mixtures will factor into a Bayes factor for the equality constraints and a conditional Bayes factor for the inequality constraints given the equality constraints [see @sarafoglou2020evaluatingPreprint, for the proof].

### The Bayes Factor For Equality Constraints

\noindent In \textbf{multibridge} the Bayes factor for the equality constraints can be computed analytically both for binomial and multinomial models using the functions \texttt{binom\_bf\_equality} and \texttt{mult\_bf\_equality}. For binomial models, assuming that the all binomial probabilities in a model are exactly equal, the Bayes factor is defined as:
\begin{align*}
\text{BF}_{0e}
&= \cfrac{\prod_{k=1}^K \text{B}(\alpha_k \text{, } \beta_k)}{\prod_{k=1}^K \text{B}(\alpha_k + x_k\text{, } \beta_k + n_k - x_k)} \times \cfrac{\text{B}(\alpha_+ + x_+ + 1\text{, } \beta_+ + n_+ - x_+ + 1)}{\text{B}(\alpha_+ + 1\text{, }\beta_+ + 1)},
\end{align*}
where \(\text{B}(\cdot)\) denotes the beta function and \(\alpha_+ = \sum_{k=1}^K\alpha_k\), \(\beta_+ = \sum_{k=1}^K\beta_k\), \(x_+ = \sum_{k=1}^K x_k\) and \(n_+ = \sum_{k=1}^K n_k\). If all binomial probabilities in a model are assumed to be exactly equal \textit{and} equal to a predicted value \(\theta_{0}\), the Bayes factor is defined as:
\begin{align*}
\text{BF}_{0e}
&= \cfrac{\prod_{k=1}^K \text{B}(\alpha_k \text{, } \beta_k)}{\prod_{k=1}^K \text{B}(\alpha_k + x_k\text{, } \beta_k + n_k - x_k)} \times \theta_{0}^{x_+} (1 - \theta_{0})^{n_+ - x_+}.
\end{align*}
Note that \textbf{multibridge} only supports the specification of one predicted value for all binomial probabilities. The package does not support the specification of different predicted values for different binomial probabilities. The reason for this is theoretical: we believe that such hypotheses are better tested using a hierarchical structure (thus modeling the binomial probabilities as dependent).

For multinomial models, assuming that all category proportions in a model are equality constrained, the Bayes factor \(\text{BF}_{0e}\) is defined as:
\begin{align*}
\text{BF}_{0e} =  \frac{
 \text{B}\left(\alpha_{1}\text{, }\dots\text{, }\alpha_K\right)}{\text{B}\left(\alpha_1+x_1\text{, }\dots\text{, }\alpha_K+x_K\right)} \, \times 
\frac{\text{B}(\boldsymbol{\alpha}+\mathbf{x})}{\text{B}(\boldsymbol{\alpha})} \, \times  \prod_{k=1}^K \theta_{0k}^{x_k},
\end{align*}
where \(\theta_{0k}\) represent the predicted category proportions. When all category proportions are assumed to be exactly equal all \(\theta_{0k}\) are set to \(\frac{1}{K}\). Otherwise, \(\boldsymbol{\theta}_{0}\) is replaced with the user-specified predicted values.

### The Bayes Factor For Inequality Constraints

\noindent To approximate the Bayes factor for informed hypotheses, @klugkist2005bayesian derived an identity that defines the Bayes factor \(\text{BF}_{re}\) as the ratio of proportions of posterior and prior parameter space consistent with the restriction. This identity forms the basis of the encompassing prior approach. Recently, @sarafoglou2020evaluatingPreprint highlighted that these proportions can be reinterpreted as the marginal likelihoods (i.e., the normalizing constants) of the constrained posterior and constrained prior distribution:

\begin{align}
\label{Eq:klugkistIdentity}
\text{BF}_{re} &= \cfrac{\overbrace{p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathbf{x}\text{, }\mathcal{H}_e)}^{\substack{\text{Marginal likelihood of}\\\text{constrained posterior distribution}}}}{\underbrace{p(\boldsymbol{\theta} \in \mathcal{R}_r \mid  \mathcal{H}_e)}_{\substack{\text{Marginal likelihood of}\\\text{constrained prior distribution}}}}.
\end{align}
The benefit of reinterpreting the identity by @klugkist2005bayesian is that we can estimate the Bayes factor by utilizing numerical sampling methods such as bridge sampling. For that we only need to be able to sample from the constrained densities. Crucially, when using bridge sampling, it does not matter how small the constrained parameter space is in proportion to the encompassing density. This gives the method a decisive advantage over the encompassing prior approach in terms of accuracy and efficiency especially (1) when binomial and multinomial models with moderate to high number of categories (i.e., \(K > 10\)) are evaluated and (2) when relatively little posterior mass falls in the constrained parameter space.

The bridge sampling algorithm implemented in \textbf{multibridge} estimates one marginal likelihood at the time [cf., @gronau2017tutorial; @overstall2010default]. Specifically, we separately estimate the marginal likelihood for the constrained prior distribution and the marginal likelihood of the constrained posterior distribution. Here we describe how to estimate the marginal likelihood for the constrained prior distribution; the steps presented can then be applied accordingly to the posterior distribution. It should be noted that the bridge sampling algorithm implemented in \textbf{multibridge} is an adapted version of the algorithm implemented in the \texttt{R} package \textbf{bridgesampling} [@gronau2017bridgesampling] and allows for the specification of informed hypotheses on probability vectors.^[In addition, the function to compute the relative mean square error for bridge sampling estimates in \textbf{multibridge} is based on the code of the \texttt{error\_measures}-function from the \textbf{bridgesampling} package.] The bridge sampling identity for the marginal likelihood of the constrained prior distribution is defined as:

\begin{align}
    p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e) = \cfrac{\mathbb{E}_{g(\boldsymbol{\theta})}\left(p(\boldsymbol{\theta}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\theta}\in\mathcal{R}_r)h(\boldsymbol{\theta})\right)}{\mathbb{E}_{\text{prior}} \left(g(\boldsymbol{\theta})h(\boldsymbol{\theta})\right)},
    \label{Eq:bridgeidentity}
\end{align}
where the term \(h(\boldsymbol{\theta})\) refers to the bridge function proposed by @meng1996simulating, \(g(\boldsymbol{\theta})\) refers to a so-called proposal distribution, and \(p(\boldsymbol{\theta}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\theta}\in\mathcal{R}_r)\) is the part of the prior parameter space under the encompassing hypothesis that is in accordance with the constraint. To estimate the marginal likelihood, bridge sampling requires samples from the target distribution, that is, the constrained Dirichlet distribution for multinomial models and constrained beta distributions for binomial models, and samples from the proposal distribution which in principle can be any distribution with a known marginal likelihood; in \textbf{multibridge} the proposal distribution is the multivariate normal distribution. Samples from the target distribution are generated using the Gibbs sampling algorithms proposed by @damien2001sampling. For binomial models, we apply the suggested Gibbs sampling algorithm for constrained beta distributions. In the case of the multinomial models, we apply an algorithm that simulates values from constrained Gamma distributions which are then transformed into Dirichlet random variables. To sample efficiently from these distributions, \textbf{multibridge} provides a \texttt{C++} implementation of this algorithm. Samples from the proposal distribution are generated using the standard \texttt{rmvnorm}-function from the \texttt{R} package \textbf{mvtnorm}[@mvtnorm].

The efficiency of the bridge sampling method is optimal only if the target and proposal distribution operate on the same parameter space and have sufficient overlap. We therefore probit transform the samples of the constrained distributions to move the samples from the probability space to the entire real line. Subsequently, we use half of these draws to construct the proposal distribution using the method of moments. Details on the probit transformations are provided in the appendix.

The numerator in Equation \ref{Eq:bridgeidentity} evaluates the unnormalized density for the constrained prior distribution with samples from the proposal distribution. The denominator evaluates the normalized proposal distribution with samples from the constrained prior distribution. Using this identity, we obtain the bridge sampling estimator for the marginal likelihood of the constrained prior distribution by applying the iterative scheme proposed by @meng1996simulating:

\begin{align*}
    \hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t+1)} \approx \cfrac{\cfrac{1}{N_2} \sum_{m = 1}^{N_2} \cfrac{\ell_{2,m}}{s_1 \ell_{2,m} + s_2 p(\boldsymbol{\tilde \theta_m} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t)}}}
    {\cfrac{1}{N_1} \sum_{n = 1}^{N_1} \cfrac{1}{s_1 \ell_{1,n} + s_2 p(\boldsymbol{\theta^*_n} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t)}}},
    %\label{Eq:bridgeIterativeScheme}
\end{align*}
where \(N_1\) denotes the number of samples drawn from the constrained distribution, that is, \(\boldsymbol{\theta}^* \sim p(\boldsymbol{\theta} \mid \mathcal{H}_r)\), \(N_2\) denotes the number of samples drawn from the proposal distribution, that is \(\boldsymbol{\tilde \theta} \sim g(\boldsymbol{\theta})\),
\(s_1 = \frac{N_1}{N_2 + N_1}\), and \(s_2 = \frac{N_2}{N_2 + N_1}\). The quantities \(\ell_{1,n}\) and \(\ell_{2,m}\) are defined as follows:

\begin{align}
    \ell_{1,n} &= \cfrac{q_{1,1}}{q_{1,2}}  = \cfrac{p(\boldsymbol{\theta^*_n}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\theta^*_n}\in\mathcal{R}_r)}{g(\boldsymbol{\xi_n}^*)},\\
    \ell_{2,m} &= \cfrac{q_{2,1}}{q_{2,2}} = \cfrac{p(\boldsymbol{\tilde \theta_m}\mid \mathcal{H}_e) \mathbb{I}(\boldsymbol{\tilde \theta_m}\in\mathcal{R}_r)}{g(\boldsymbol{\tilde \xi_m})},
\end{align}
where \(\boldsymbol{\xi_n}^* = \Phi^{-1}\left(\cfrac{\boldsymbol{\theta^*_n} - \mathbf{l}}{\mathbf{u} - \mathbf{l}}\right)\), and \(\boldsymbol{\tilde \theta_m} = ((\mathbf{u} - \mathbf{l})\Phi(\boldsymbol{\tilde \xi_m}) + \mathbf{l}) \left|J\right|)\). The quantity \(q_{1,1}\) refers to the evaluations of the constrained distribution for constrained samples and \(q_{1,2}\) refers to the proposal distribution evaluated at the probit-transformed samples from the constrained distribution, respectively. The quantity \(q_{2,1}\) refers to evaluations of the constrained distribution at the inverse probit-transformed samples from the proposal distribution and \(q_{2,2}\) refers to the proposal evaluations for samples from the proposal, respectively. Note that the quantities \(\ell_{1,n}\) and \(\ell_{2,m}\) have been adjusted to account for the necessary parameter transformations to create overlap between the constrained distributions and the proposal distribution. \textbf{multibridge} runs the iterative scheme until the tolerance criterion suggested by @gronau2017tutorial is reached, that is:
\begin{align*}
\cfrac{\mid \hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t + 1)} - \hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t)} \mid}{\hat p(\boldsymbol{\theta} \in \mathcal{R}_r \mid \mathcal{H}_e)^{(t + 1)}} &\leq 10^{-10}.
\end{align*}
The sampling from the target and proposal distribution, the transformations and computational steps are performed automatically within the core functions of \textbf{multibridge}. The user only needs to provide the functions with the data, a prior and a specification of the informed hypothesis. As part of the standard output of \texttt{binom\_bf\_informed} and \texttt{mult\_bf\_informed}, the functions return the bridge sampling estimate for the log marginal likelihood of the target distribution, its associate relative mean square error, the number of iterations, and the quantities \(q_{1,1}\), \(q_{1,2}\), \(q_{2,1}\), and \(q_{2,2}\).

# Usage and Examples

\noindent In the following, we will outline two examples on how to use \textbf{multibridge} to compare an informed hypothesis to a null or encompassing hypothesis. The first example concerns multinomial data and the second example concerns independent binomial data.


```{r, echo = FALSE}
library('multibridge')
```

A list of all currently available functions and data sets is given in Table \ref{table:core_functions}. Additional examples are available as vignettes (see \texttt{vignette(package\ =\ "multibridge")}). The two core functions of \textbf{multibridge}---\texttt{mult\_bf\_informed} and the \texttt{binom\_bf\_informed}---can be illustrated schematically as follows:

```{r, eval=FALSE, echo=TRUE}
mult_bf_informed(x, Hr, a, factor_levels)
binom_bf_informed(x, n, Hr, a, b, factor_levels)
```


\begin{table}[H]
\caption {Core functions available in $\textbf{multibridge}$.}
\label{table:core_functions}
\begin{center}
\begin{tabular}{p{5.5cm}p{10.5cm}}
        \toprule
Function Name(s) & Description \\\midrule
$\texttt{mult\_bf\_informed}$ & Evaluates informed hypotheses on multinomial parameters.  \\
$\texttt{mult\_bf\_inequality}$ & Estimates the marginal likelihood of a constrained prior or posterior Dirichlet distribution.  \\
$\texttt{mult\_bf\_equality}$ & Computes Bayes factor for equality constrained multinomial parameters using the standard Bayesian multinomial test.  \\
$\texttt{mult\_tsampling}$ & Samples from constrained prior or posterior Dirichlet density.\\
$ \texttt{lifestresses}, \texttt{peas}$ & Data sets associated with informed hypotheses in multinomial models.\\\midrule
$\texttt{binom\_bf\_informed}$ & Evaluates informed hypotheses on binomial parameters.  \\
$\texttt{binom\_bf\_inequality}$ & Estimates the marginal likelihood of constrained prior or posterior beta distributions.\\
$\texttt{binom\_bf\_equality}$ & Computes Bayes factor for equality constrained binomial parameters. \\
$\texttt{binom\_tsampling}$ & Samples from constrained prior or posterior beta densities.\\
$ \texttt{journals}$ & Data set associated with informed hypotheses in binomial models.\\\midrule
$ \texttt{generate\_restriction\_list}$ & Encodes the informed hypothesis.\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

## Example 1: Applying A Benford Test to Greek Fiscal Data

\noindent The first-digit phenomenon, otherwise known as Benford's law [@benford1938law; @newcomb1881note] states that the expected proportion of leading digits in empirical data can be formalized as follows: for any given leading digit \(d, d = (1, \cdots, 9)\) the expected proportion is approximately equal to \[\mathbb{E}_{\theta_d}= \text{log}_{10}((d + 1)/d).\] This means that in an empirical data set, numbers with smaller leading digits are more common than numbers with larger leading digits. Specifically, a number has leading digit \(1\) in \(30.1 \%\) of the cases, and leading digit \(2\) in \(17.61 \%\) of the cases; leading digit \(9\) is the least frequent digit with an expected proportion of only \(4.58 \%\) (see Table \ref{Tab:benford} for an overview of the expected proportions). Empirical data for which this relationship holds include population sizes, death rates, baseball statistics, atomic weights of elements, and physical constants [@benford1938law]. In contrast, artificially generated data, such as telephone numbers, do in general not obey Benford's law [@hill1995statistical]. Given that Benford's law applies to empirical data but not artificially generated data, a so-called Benford test can be used in fields like accounting and auditing to check for indications for poor data quality [for an overview, see e.g., @durtschi2004effective; @nigrini1997use; @nigrini2012benford]. Data that do not pass the Benford test, should raise audit risk concerns, meaning that it is recommended that they undergo additional follow-up checks (Nigrini, 2019).

Below we discuss four possible Bayesian adaptations of the Benford test. In a first scenario we simply conduct a Bayesian multinomial test in which we test the point-null hypothesis \(\mathcal{H}_0\) which predicts a Benford distribution against the encompassing hypothesis \(\mathcal{H}_{e}\). In a second scenario we test the null hypothesis against an alternative hypothesis, denoted as \(\mathcal{H}_{r1}\), which predicts a decreasing trend in the proportions of leading digits. The hypothesis \(\mathcal{H}_{r1}\) exerts considerably more constraint than \(\mathcal{H}_{e}\) and provides a more sensitive test if our primary goal is to test whether data comply with Benford's law or whether the data follow a similar but different trend. In the next two scenarios, our main goal is to identify fabricated data. The third scenario therefore tests the null hypothesis against the hypothesis that all proportions occur equally often. This hypothesis \(\mathcal{H}_{r2}\) could be considered if it is suspected that the data were generated randomly. In a fourth scenario we test the null hypothesis against a hypothesis which predicts a trend that is characteristic for manipulated data. This hypothesis, which we denote as \(\mathcal{H}_{r3}\), could be derived from empirical research on fraud or be based on observed patterns from former fraud cases. For instance, @hill1995statistical instructed students to produce a series of random numbers; in the resulting data the proportion of the leading digit \(1\) occurred most often and the digits \(8\) and \(9\) occurred least often which is consistent with the general pattern of Benford's law. However, the proportion for the remaining leading digits were approximately equal. Note that the predicted distribution derived from @hill1995statistical is not currently used as a test to detect fraud. However, for the sake of simplicity, if we assume that this pattern could be an indication of manipulated auditing data, the Bayes factor \(\text{BF}_{0r3}\) would quantify the evidence of whether the proportion of first digits resemble authentic or fabricated data.

### Data and Hypothesis

The data we use to illustrate the computation of Bayes factors were originally published by the European statistics agency \enquote{Eurostat} and served as basis for reviewing the adherence to the Stability and Growth Pact of EU member states. @rauch2011fact conducted a Benford test on data related to budget deficit criteria, that is, public deficit, public dept and gross national products. The data used for this example features the proportion of first digits from Greek fiscal data in the years between \(1999\) and \(2010\); a total of \(N= 1{,}497\) numerical data were included in the analysis. We choose this data, since the Greek government deficit and debt statistics states has been repeatedly criticized by the European Commission in this time span [@europeanCommision2004; @europeanCommision2010]. In particular, the commission has accused the Greek statistical authorities to have misreported deficit and debt statistics. For further details on the data set see @rauch2011fact. The observed and expected proportions are displayed in Table \ref{Tab:benford}; the expected proportions versus the posterior parameter estimates under the encompassing hypothesis are displayed in Figure \ref{fig:benford-alt}.

\begin{table}[H]
	\centering
	\caption{Observed counts, observed proportions, and expected proportions of first digits in the Greek fiscal data set. The total sample size was $N = 1{,}497$ observations. Note that the observed proportions and counts deviate slightly from those reported in Rauch et al. (2011) (probably due to rounding errors).}
	\begin{tabular}{cccp{4cm}}
		\hline
Leading digit & Observed Counts & Observed Proportions & Expected Proportions: Benford's Law  \\
		\hline
		1 & 509 & 0.340 & 0.301  \\
		2 & 353 & 0.236 & 0.176  \\
		3 & 177 & 0.118 & 0.125  \\
		4 & 114 & 0.076 & 0.097  \\
		5 & 77 & 0.051 & 0.079  \\
		6 & 77 & 0.051 & 0.067  \\
		7 & 53 & 0.035 & 0.058  \\
		8 & 73 & 0.049 & 0.051  \\
		9 & 64 & 0.043 & 0.046  \\
		\hline
	\end{tabular}
    \label{Tab:benford}
\end{table}

In this example, the parameter vector of the multinomial model, \(\theta_1, \cdots, \theta_K\), reflects the probabilities of a leading digit in the Greek fiscal data being a number from \(1\) to \(9\). The hypotheses introduced above can then be formalized as follows. The null hypothesis specifies that the proportions of first digits obeys Benford's law:
\[\mathcal{H}_0 : \boldsymbol{\theta}_0 = (0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046).\] This null hypothesis can then be tested against each of the following four alternative hypotheses:
\begin{align*}
\mathcal{H}_e &: \boldsymbol{\theta} \sim \text{Dirichlet}(\mathbf{1}), \\
\mathcal{H}_{r1} &: \theta_1 > \theta_2 > \theta_3 > \theta_4 > \theta_5 > \theta_6 > \theta_7 > \theta_8 > \theta_9, \\
\mathcal{H}_{r2} &:  \boldsymbol{\theta}_0 = \left(\frac{1}{9}, \frac{1}{9}, \frac{1}{9}, \frac{1}{9}, \frac{1}{9}, \frac{1}{9}, \frac{1}{9}, \frac{1}{9}, \frac{1}{9}\right),\\
\mathcal{H}_{r3} &:  \theta_1 > (\theta_2 = \theta_3 = \theta_4 = \theta_5 = \theta_6 = \theta_7) > (\theta_8, \ \theta_9).
\end{align*}
The comparison of any two informed hypotheses with one another follows from the fact that Bayes factors are transitive. For instance, the Bayes factor comparison between \(\mathcal{H}_{0}\) and \(\mathcal{H}_{r1}\) can be obtained by first computing \(\text{BF}_{e0}\) and \(\text{BF}_{er1}\), and then dividing out the common hypothesis \(\mathcal{H}_{e}\):
\[\text{BF}_{0r1} = \frac{\text{BF}_{e0}}{\text{BF}_{er1}}.\] 

An overview of the relative plausibility of all $M=5$ models simultaneously may be obtaining by presenting the posterior model probabilities $p(\mathcal{H}_i \, | \, x)$ (Berger \& Molina, 2005). Denoting the prior model probability for model $\mathcal{H}_i$ by $p(\mathcal{H}_i)$, the posterior model probability for $\mathcal{H}_0$ is given by:

\[ p(\mathcal{H}_0 \mid \mathbf{x}) = \cfrac{\cfrac{p(\mathbf{x} \mid \mathcal{H}_0)}{p(\mathbf{x} \mid \mathcal{H}_e)} \times p(\mathcal{H}_0)}{\displaystyle\sum\limits_{i = 1}^M \cfrac{p(\mathbf{x} \mid \mathcal{H}_i)}{p(\mathbf{x} \mid \mathcal{H}_e)} \times p(\mathcal{H}_i)}.\]

\noindent When all hypotheses are equally likely \emph{a priori}, this simplifies to:
\[
p(\mathcal{H}_0 \mid \mathbf{x}) = \cfrac{\text{BF}_{0e}}{\text{BF}_{0e} + \text{BF}_{r1e} + \text{BF}_{r2e} + \text{BF}_{r3e} + \text{BF}_{ee}} .
\]

### Method
Both \(\text{BF}_{0e}\) and \(\text{BF}_{r2e}\) may be readily computed by means of a Bayesian multinomial test which is implemented in the function \texttt{mult\_bf\_equality}. This function requires (1) a vector with observed counts, (2) a vector with concentration parameters of the Dirichlet prior distribution under $\mathcal{H}_e$, and (3) the vector of expected proportions under $\mathcal{H}_0$ and under $\mathcal{H}_{r2}$. We do not incorporate specific expectations about the distribution of leading digits in the Greek fiscal data and therefore set all concentration parameters under $\mathcal{H}_e$ to 1 (i.e., we assign $\boldsymbol{\theta}$ a uniform Dirichlet prior distribution).

```{r, message=FALSE, echo = TRUE, results='hide'}
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Concentration parameters
a <-  rep(1, 9)
# Expected proportions for H_0 and H_r2
p0  <- log10((1:9 + 1)/1:9)
pr2 <- rep(1/9, 9)
# Execute the analysis
results_H0_He   <- mult_bf_equality(x = x, a = a, p = p0)
results_Hr2_He  <- mult_bf_equality(x = x, a = a, p = pr2)

logBFe0  <- results_H0_He$bf$LogBFe0
logBFer2 <- results_Hr2_He$bf$LogBFe0
```

The hypotheses \(\mathcal{H}_{r1}\) and \(\mathcal{H}_{r3}\) contain inequality constraints, and this necessitates the use of the function \texttt{mult\_bf\_informed} to compute the Bayes factors \(\text{BF}_{r1e}\) and \(\text{BF}_{r3e}\). This function requires (1) a vector with observed counts, (2) a vector with concentration parameters of the Dirichlet prior distribution under $\mathcal{H}_e$, (3) labels for the categories of interest (i.e., leading digits), and (4) the informed hypothesis \(\mathcal{H}_{r1}\) or \(\mathcal{H}_{r3}\) (e.g., as a string):

```{r, message=FALSE, echo = TRUE, results='hide'}
# Observed counts
x <- c(509, 353, 177, 114,  77,  77,  53,  73,  64)
# Prior specification for Dirichlet prior distribution under H_e
a <-  rep(1, 9)
# Labels for categories of interest
factor_levels <- 1:9
# Specifying the informed hypotheses as a string
Hr1 <- c('1 > 2 > 3 > 4 > 5 > 6 > 7 > 8 > 9')
Hr3 <- c('1 > 2 = 3 = 4 = 5 = 6 = 7 > 8 > 9')
# Execute the analysis
results_He_Hr1 <- mult_bf_informed(x = x, Hr = Hr1, a = a, 
                                 factor_levels = factor_levels, 
                                 bf_type = 'LogBFer', seed = 2020)
logBFer1 <- summary(results_He_Hr1)$bf
results_He_Hr3 <- mult_bf_informed(x = x, Hr = Hr3, a = a, 
                                 factor_levels = factor_levels, 
                                 bf_type = 'LogBFer', seed = 2020)
logBFer3 <- summary(results_He_Hr3)$bf
```

We may now exploit transitivity to compare all alternative hypotheses to the Benford null hypothesis \(\mathcal{H}_{0}\). We also compute the posterior model probabilities for all hypotheses. The results are shown in Table~\ref{Tab:benfordResults}.


```{r, echo = FALSE}
bayes_factors <- data.frame(
   BFType = c('LogBFe0', 'LogBFr10', 'LogBFr20', 'LogBFr30'), 
   LogBF  = c(logBFe0, -logBFer1 + logBFe0, -logBFer2 + logBFe0, -logBFer3 + logBFe0))

denominator <- c(1, exp(bayes_factors$LogBF))
post_probs <- data.frame(
   Hyps = c('p(H0 | x)', 'p(He | x)', 'p(Hr1 | x)', 'p(Hr2 | x)', 'p(Hr3 | x)'), 
   Prob = denominator/sum(denominator))
```

\begin{table}[H]
	\centering
	\caption{Prior model probabilities, posterior model probabilities, and Bayes factors for five rival accounts of first digit frequencies in the Greek fiscal data set.}
	\begin{tabular}{ccll}
		\hline Hypothesis &  $p(\mathcal{H}_{.})$ & $p(\mathcal{H}_{.} \mid \mathbf{x})$ & $\text{log}(\text{BF}_{.0})$ \\
		\hline
		$\mathcal{H}_{0}$  & $0.2$  &
		`r papaja::printnum(post_probs[1, 2], digits = 2, format = 'e')` & $0$ \\
		$\mathcal{H}_{r1}$ & $0.2$ &
		`r papaja::printnum(post_probs[3, 2], digits = 4, format = 'f')` & 
		`r papaja::printnum(bayes_factors[2, 2], digits = 2)`\\
		$\mathcal{H}_{e}$  & $0.2$ &
		`r papaja::printnum(post_probs[2, 2], digits = 4, format = 'f')` & 
		`r papaja::printnum(bayes_factors[1, 2], digits = 2)`\\
		$\mathcal{H}_{r3}$ & $0.2$ &
		`r papaja::printnum(post_probs[5, 2], digits = 2, format = 'e')` &
		`r papaja::printnum(bayes_factors[4, 2], digits = 2)`\\
		$\mathcal{H}_{r2}$ & $0.2$ &
		`r papaja::printnum(post_probs[4, 2], digits = 2, format = 'e')` & 
		`r papaja::printnum(bayes_factors[3, 2], digits = 2)`\\
		\hline
	\end{tabular}
    \label{Tab:benfordResults}
\end{table}

The results indicate strong support for $\mathcal{H}_{r1}$ --the model in which the proportions are assumed to decrease monotonically-- over all other models. The log Bayes factor of $\mathcal{H}_{r1}$ against Benford's law $\mathcal{H}_0$ is an overwhelming `r papaja::printnum(bayes_factors[2, 2], digits = 2, format = 'f')`; the evidence for $\mathcal{H}_{r1}$ is even stronger when it is compared against models that feature equality constraints (i.e., $\mathcal{H}_{r2}$ and $\mathcal{H}_{r3}$). Finally, $\mathcal{H}_{r1}$ also outperforms model $\mathcal{H}_{e}$, the unconstrained model in which all parameters are free to vary. The latter result demonstrates how a parsimonious model that makes precise predictions can be favored over a model that is more complex [e.g., @jefferysberger1992]. The strong Bayes factor support for $\mathcal{H}_{r1}$ translates to a relatively extreme posterior model probability of `r papaja::printnum(post_probs[3, 2], digits = 4, format = 'f')`.

(ref:benford-alt-caption) Predictions from Benford's law (in grey) show together with the posterior medians (black circles) for the category proportions estimated under the encompassing model $\mathcal{H}_e$. The circle skewers show the 95\% credible intervals. Only three of nine intervals encompass the expected proportions, suggesting that the data do not follow Benford's law. This plot was created using the \texttt{plot}-S3-method for \texttt{summary.bmult} objects in \textbf{multibridge}.}

```{r benford-alt, echo = FALSE, message = FALSE, fig.cap = "(ref:benford-alt-caption)"}
first_digits <- 1:9
benford <- log10((first_digits + 1) / first_digits)

plot(
  summary(results_He_Hr1)
  , xlab = "Leading digit"
  # , ylab = "Proportion"
  , main = ""
  , panel.first = {
    lines(x = first_digits, y = benford, lty = "22", col = grey(0.5))
    points(x = first_digits, y = benford, pch = 16, col = "white", cex = 2)
    points(x = first_digits, y = benford, pch = 16, bg = "white", col = grey(0.7), cex = 0.8)
  }
)

points(x = first_digits, y = benford, pch = 16, bg = "white", col = grey(0.7), cex = 0.8)

legend(
  "right"
  , legend = c("Benford", "Posterior")
  , col = c(grey(0.7), "black")
  , pch = c(16, 21)
  , pt.bg = c(NULL, "white")
  , lty = c("22", "solid")
  , lwd = c(1.25, 1)
  , bty = "n"
  , pt.cex = c(0.8, 1.5)
  , title = "Distribution"
  , seg.len = 1.5
)
```

To summarize, the data offer overwhelming support for hypothesis \(\mathcal{H}_{r1}\), which postulates a decreasing trend in the digit proportions. This model outperformed both simpler models (e.g., the Benford model) and a more complex model in which the proportions were free to vary.
Detailed follow-up analyses are needed to discover why the data follow a monotonically decreasing pattern but not any of the two specific patterns that were put to the test [@nigrini2019patterns]. 

## Example 2: Prevalence of Statistical Reporting Errors

\noindent This section illustrates how \textbf{multibridge} may be used to evaluate models for independent binomial data rather than multinomial data. Our example concerns the prevalence of statistical reporting errors across eight different psychology journals. In any article that uses null hypothesis significance testing, there is a chance that the reported test statistic and degrees of freedom do not match the reported \(p\)-value, possibly because of copy-paste errors. To flag these errors, @epskamp2014statcheck developed the R package \texttt{statcheck}, which scans the PDF of a given scientific article and automatically detects statistical inconsistencies. This package allowed @nuijten2016prevalence to estimate the prevalence of statistical reporting errors in the field of psychology. In total, the authors investigated a sample of \(30{,}717\) articles (which translates to over a quarter of a million \(p\)-values) published in eight major psychology journals between 1985 to 2013: \emph{Developmental Psychology} (DP), the \emph{Frontiers in Psychology} (FP), the \emph{Journal of Applied Psychology} (JAP), the \emph{Journal of Consulting and Clinical Psychology} (JCCP), \emph{Journal of Experimental Psychology: General} (JEPG), the \emph{Journal of Personality and Social Psychology} (JPSP), the \emph{Public Library of Science} (PLoS), \emph{Psychological Science} (PS).

Based on several background assumptions, @nuijten2016prevalence predicted that the proportion of statistical reporting errors is higher for articles published in the \emph{Journal of Personality and Social Psychology} (JPSP) than for articles published in the seven other journals.

### Data and Hypothesis

Here we reuse the original data published by @nuijten2016prevalence, which we also distribute with the package \textbf{multibridge} under the name \texttt{journals}.

```{r, echo = TRUE}
data(journals)
```

The nuijten2016prevalence hypothesis of interest, \(\mathcal{H}_r\), states that the prevalence for statistical reporting errors is higher for JPSP than for the other journals.^[@nuijten2016prevalence did not report inferential tests because they had sampled the entire population. We do report inferential tests here because we wish to learn about the latent data-generating process.] We will consider two specific versions of the @nuijten2016prevalence \(\mathcal{H}_r\) hypothesis. The first hypothesis, \(\mathcal{H}_{r1}\), stipulates that JPSP has the highest prevalence of reporting inconsistencies, whereas the other seven journals share a prevalence that is lower. The second hypothesis, \(\mathcal{H}_{r2}\), also stipulates that JPSP has the highest prevalence of reporting inconsistencies, but does not commit to any particular structure on the prevalence for the other seven journals.

The \textbf{multibridge} package can be used to test \(\mathcal{H}_{r1}\) and \(\mathcal{H}_{r2}\) against the null hypothesis \(\mathcal{H}_0\) that all eight journals have the same prevalence of statistical reporting errors. In addition, we will compare \(\mathcal{H}_{r1}\), \(\mathcal{H}_{r2}\), and \(\mathcal{H}_0\) against the encompassing hypothesis \(\mathcal{H}_e\) that makes no commitment whatsoever about the prevalence of reporting inconsistencies across the eight journals. In this example, the parameter vector of the binomial success probabilities, \(\boldsymbol{\theta}\), reflects the probabilities that articles contain at least one statistical reporting inconsistency across journals. Thus, the above hypotheses can be formalized as follows:

\begin{align*}
    \mathcal{H}_0 &: \theta_{\text{DP}} = \theta_{\text{FP}} = \theta_{\text{JAP}} = \theta_{\text{JCCP}} = \theta_{\text{JEPG}} = \theta_{\text{PLoS}}= \theta_{\text{PS}} = \theta_{\text{JPSP}}\\
    \mathcal{H}_{r1} &: (\theta_{\text{DP}} = \theta_{\text{FP}} = \theta_{\text{JAP}} = \theta_{\text{JCCP}} = \theta_{\text{JEPG}} = \theta_{\text{PLoS}}= \theta_{\text{PS}}) < \theta_{\text{JPSP}} \\
    \mathcal{H}_{r2} &: (\theta_{\text{DP}}, \theta_{\text{FP}}, \theta_{\text{JAP}} , \theta_{\text{JCCP}} , \theta_{\text{JEPG}} , \theta_{\text{PLoS}}, \theta_{\text{PS}}) < \theta_{\text{JPSP}} \\
    \mathcal{H}_e &:  \theta_{\text{DP}} \cdots \theta_{\text{JPSP}} \sim \prod_{k = 1}^K \text{Beta}(\alpha_k, \beta_k).
\end{align*}

### Method

To compute the Bayes factor \(\text{BF}_{0r}\) we need to specify (1) a vector with observed successes (i.e., the number of articles that contain a statistical inconsistency), (2) a vector containing the total number of observations (i.e., the number of articles), (3) a vector with prior parameter \(\alpha_k\) for each binomial proportion of the beta prior distribution under \(\mathcal{H}_e\), (4) a vector with prior parameter \(\beta_k\) for each binomial proportion of the beta prior distribution under \(\mathcal{H}_e\), (5) the category labels (i.e., journal names), and (6) the informed hypothesis \(\mathcal{H}_{r1}\) or \(\mathcal{H}_{r2}\) (e.g., as a string). Since we have no specific expectations about the distribution of statistical reporting errors in any given journal, we set all parameters \(\alpha_k\) and \(\beta_k\) to one which corresponds to uniform beta distributions. With this information, we can now conduct the analysis with the function \texttt{binom\_bf\_informed}.

```{r, echo=TRUE, message=FALSE, results='hide'}
# Since percentages are rounded to two decimal values, we round the
# articles with an error to obtain integer values
x <- round(journals$articles_with_NHST  * 
             (journals$perc_articles_with_errors/100))
# Total number of articles
n <- journals$articles_with_NHST

# Prior specification for beta prior distributions under H_e
a <- rep(1, 8)
b <- rep(1, 8)

# Labels for categories of interest
journal_names <- journals$journal

# Specifying the informed Hypothesis
Hr1 <- c('JAP = PS = JCCP = PLOS = DP = FP = JEPG < JPSP')
Hr2 <- c('JAP , PS , JCCP , PLOS , DP , FP , JEPG < JPSP')

# Execute the analysis for Hr1
results_H0_Hr1 <- binom_bf_informed(x = x, n = n, Hr = Hr1, a = a, b = b,
                                factor_levels = journal_names,
                                bf_type = 'LogBFr0', seed = 2020)
# Execute the analysis for Hr2
results_H0_Hr2 <- binom_bf_informed(x = x, n = n, Hr = Hr2, a = a, b = b,
                                factor_levels = journal_names,
                                bf_type = 'LogBFr0', seed = 2020)
```

```{r, echo = TRUE}
LogBFe0  <- results_H0_Hr1$bf_list$bf0_table[['LogBFe0']]
LogBFr10 <- summary(results_H0_Hr1)$bf
LogBFr20 <- summary(results_H0_Hr2)$bf
```

```{r, echo = FALSE}
LogBFr1e <- -results_H0_Hr1$bf_list$bfr_table[['LogBFer']]
LogBFr2e <- -results_H0_Hr2$bf_list$bfr_table[['LogBFer']]

bayes_factors <- data.frame(
   BFType = c('LogBFe0', 'LogBFr10', 'LogBFr20'), 
   BF = c(LogBFe0, LogBFr10, LogBFr20))

denominator <- sum(1, exp(-LogBFe0), exp(LogBFr1e), exp(LogBFr2e))
post_probs <- data.frame(
   Hyps = c('p(He | x)', 'p(H0 | x)', 'p(Hr1 | x)' , 'p(Hr2 | x)'), 
   Prob = c(1, exp(-LogBFe0), exp(LogBFr1e), exp(LogBFr2e))/denominator)
```


\begin{table}[H]
    \centering
    \caption{Prior model probabilities, posterior model probabilities, and Bayes factors for four hypotheses concerning the prevalence of statistical reporting errors across psychology journals.}
    \begin{tabular}{ccll}
        \hline Hypothesis & $p(\mathcal{H}_{.})$ & $p(\mathcal{H}_{.} \mid \mathbf{x})$ & $\text{log}(\text{BF}_{.0})$ \\
        \hline
        $\mathcal{H}_{0}$  & $0.25$ & 
        `r papaja::printnum(post_probs[2, 2], digits = 4, format = 'e')` & 
        $0$ \\
        $\mathcal{H}_{r2}$ & $0.25$ & 
        `r papaja::printnum(post_probs[4, 2], digits = 4, format = 'f')` &  
        `r papaja::printnum(bayes_factors[3, 2], digits = 2, format = 'f')`\\
        $\mathcal{H}_{e}$  &  $0.25$  & 
        `r papaja::printnum(post_probs[1, 2], digits = 4, format = 'f')` & 
        `r papaja::printnum(bayes_factors[1, 2], digits = 2, format = 'f')` \\
        $\mathcal{H}_{r1}$  &  $0.25$  & 
        `r papaja::printnum(post_probs[3, 2], digits = 4, format = 'e')` & 
        `r papaja::printnum(bayes_factors[2, 2], digits = 2, format = 'f')` \\
        \hline
    \end{tabular}
    \label{Tab:journalsResults}
\end{table}

\noindent As the evidence is extreme in all four cases, we again report all Bayes factors on the log scale. The Bayes factor \(\text{log}(\text{BF}_{r20})\) indicates overwhelming evidence for the informed hypothesis that JPSP has the highest prevalence for statistical reporting inconsistencies compared to the null hypothesis that the statistical reporting errors are equal across all eight journals; \( \text{log}(\text{BF}_{r20}) = \) `r papaja::printnum(bayes_factors[3, 2], digits = 2, format = 'f')`.

(ref:journals-caption) Posterior medians for the prevalence of statistical reporting inconsistencies across eight psychology journals, as obtained using the encompassing model. The circle skewers show the 95\% credible intervals. Analysis based on data from @nuijten2016prevalence. This plot was created using the \texttt{plot}-S3-method for \texttt{summary.bmult} objects.

```{r journals, echo = FALSE, message = FALSE, fig.cap = "(ref:journals-caption)"}
plot(summary(results_H0_Hr2), xlab = "Journal")
```

For a clearer picture about the ordering of the journals we can investigate the posterior distributions for the prevalence rates obtained under the encompassing model. The posterior medians and 95\% credible intervals are returned by the \texttt{summary}-method and are shown in Figure \ref{fig:journals}. The figure strongly suggests that the prevalence of reporting inconsistencies is not equal across all eight journals. This impression may be quantified by comparing the null hypothesis \(\mathcal{H}_0\) to the encompassing hypothesis \(\mathcal{H}_e\). The corresponding Bayes factor equals \( \text{log}(\text{BF}_{e0}) = \) `r papaja::printnum(bayes_factors[1, 2], digits = 2, format = 'f')`, which confirms that the data dramatically undercut the null hypothesis that the prevalence of statistical reporting inconsistencies is equal across journals.

The data offer most support for the Nuijten hypothesis \(\mathcal{H}_{r2}\), which posits that JPSP has the highest prevalence but does not commit to any restriction on the prevalences for the remaining seven journals. This hypothesis may be compared to the encompassing hypothesis \(\mathcal{H}_e\), which yields \( \text{log}(\text{BF}_{r2e}) = \) `r papaja::printnum(LogBFr2e, digits=2, format = 'f')`. This means that the observed data are \(\exp(2.01) \approx 7.45\) times more likely under \(\mathcal{H}_{r2}\) than under \(\mathcal{H}_e\); this is moderate evidence for the restriction suggested by @nuijten2016prevalence. Under equal prior probability for the models, this Bayes factor translates to a posterior probability on \(\mathcal{H}_e\) of `r papaja::printnum(post_probs[1, 2], digits = 3, format = 'f')`, an amount that researchers may deem too large to discard in an all-or-none fashion.

To summarize, the data provide moderate evidence for the hypothesis stated by Nuijten et al. (2016) that the prevalence of statistical reporting inconsistencies in JPSP is higher than that in seven other psychology journals.

# Summary

The \texttt{R} package \textbf{multibridge} facilitates the estimation of Bayes factors for informed hypotheses in both multinomial and independent binomial models. The efficiency gains of \textbf{multibridge} are particularly pronounced when the parameter restrictions are highly informative or when the number of categories is large.

\textbf{multibridge} supports the evaluation of informed hypotheses that feature equality constraints, inequality constraints, and free parameters, as well as mixtures between them. Moreover, users can choose to test the informative hypothesis against an encompassing hypothesis that lets all parameters vary freely or against the null hypothesis that states that category proportions are exactly equal. Beyond the core functions currently implemented in \textbf{multibridge}, there are several natural extensions we aim to include in future versions of this package. For instance, to compare several models with each other we plan to implement functions that compute the posterior model probabilities. Another extension is to facilitate the specification of hierarchical binomial and multinomial models which would allow users to analyze data where responses are nested within a higher-order structure such as participants, schools, or countries. Hierarchical multinomial models can be found, for instance, in source memory research where people need to select a previously studied item from a list [e.g., @arnold2019testing]. In addition, we aim to enable the specification of informed hypotheses that are more complex, including hypotheses on the size ratios of the parameters (e.g., $\theta_1 < 2 \times \theta_2$) of interest or the difference between category proportions such that informed hypotheses can also be specified on odds ratios (e.g., $\frac{\theta_1}{(\theta_1 + \theta_2)} < \frac{\theta_3}{(\theta_3 + \theta_4)}$).

# Acknowledgements
This research was supported by a Netherlands Organisation for Scientific Research (NWO) grant
to AS (406-17-568), a Veni grant from the NWO to MM (451-17-017), a Vici grant from the NWO to EJW (016.Vici.170.083), as well as a a European Research Council (ERC) grant to EJW (283876).

\clearpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

\clearpage

```{r echo = FALSE, results = 'asis', cache = FALSE, child = "Rpackage_appendix.Rmd"}
# papaja::render_appendix('Rpackage_appendix.Rmd')
```

